{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lxIMTrZbqYW",
        "outputId": "c99aed18-9e84-43c3-bcd1-fa14789b0936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PYhMzEpb2-NX"
      },
      "outputs": [],
      "source": [
        "from scipy.io.wavfile import read\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U0L_UV0hC-a",
        "outputId": "eecb290f-4425-41ab-f4df-6815a0760d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'heart failure', 'heart failure', 'heart failure', 'copd', 'copd', 'copd', 'copd', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'heart failure', 'heart failure', 'heart failure', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'heart failure', 'heart failure', 'heart failure', 'copd', 'copd', 'copd', 'copd', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'heart failure', 'heart failure', 'heart failure', 'copd', 'copd', 'copd', 'copd', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'bron', 'bron', 'bron', 'bron', 'bron', 'bron', 'heart failure', 'heart failure', 'heart failure', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'pneumonia', 'pneumonia', 'pneumonia', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'pneumonia', 'pneumonia', 'pneumonia', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'pneumonia', 'pneumonia', 'pneumonia', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'n', 'n', 'n', 'n', 'n', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'n', 'n', 'n', 'n', 'n', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'n', 'n', 'n', 'n', 'n', 'asthma', 'asthma', 'asthma', 'asthma', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'lung fibrosis', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'n', 'n', 'n', 'n', 'n', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'n', 'n', 'n', 'n', 'n', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'asthma', 'asthma', 'asthma', 'asthma', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'plueral effusion', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma', 'asthma', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'copd', 'asthma', 'asthma', 'asthma', 'asthma', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'heart failure', 'asthma', 'asthma', 'asthma']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def preprocess(directories):\n",
        "  x_data = []\n",
        "  y_data = []\n",
        "  for directory in directories:\n",
        "    for filename in os.listdir(directory):\n",
        "      f = os.path.join(directory, filename)\n",
        "\n",
        "      if \"and\" in filename or \"+\" in filename:\n",
        "        continue\n",
        "\n",
        "      # Create 1d array from audio input\n",
        "      original_arr, sample_rate = torchaudio.load(f)\n",
        "      \"\"\"\n",
        "      print(sample_rate)\n",
        "      print(\"here\")\n",
        "      print(\"filename: \" + filename)\n",
        "      print(\"Lenth original: \" + str(len(original_arr[0])))\n",
        "      print(original_arr)\n",
        "      \"\"\"\n",
        "      # Loop through segments of each file\n",
        "      # Each segment will be 10000 elements long which is 2.5 seconds of audio recording\n",
        "      for i in range(0, len(original_arr[0])-10000, 10000):\n",
        "        arr = original_arr[0][i:i+10000]\n",
        "\n",
        "        arr = arr.view(-1)\n",
        "\n",
        "        # Generate MFCCs\n",
        "        # Doing it this way makes the mfccs shape (20, 137)\n",
        "        mfccs = librosa.feature.mfcc(y=arr.numpy(), sr=sample_rate)\n",
        "\n",
        "        # Generate spectrogram image\n",
        "        spectrogram = plt.specgram(arr, Fs= sample_rate)[0]\n",
        "        plt.close()\n",
        "\n",
        "        mfccs_resized = torch.FloatTensor(mfccs).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
        "\n",
        "        # Resize using interpolation to match the dimensions\n",
        "        mfccs_resized = torch.nn.functional.interpolate(mfccs_resized, size=(spectrogram.shape[0], spectrogram.shape[1]), mode='nearest')\n",
        "\n",
        "\n",
        "        # Plotting original mfccs vs resized mfccs - commented out cause it takes forever just uncomment it if you wanna see the images\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 5))\n",
        "\n",
        "        # Plot for the first graph\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(mfccs)\n",
        "        plt.title('Original')\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('Y')\n",
        "\n",
        "        # Plot for the second graph\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(mfccs_resized.squeeze().numpy())\n",
        "        plt.title('Resized')\n",
        "        #plt.colorbar(label='Value')\n",
        "        plt.xlabel('X')\n",
        "        plt.ylabel('Y')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \"\"\"\n",
        "\n",
        "        # Convert spectrogram and mfccs to PyTorch tensors\n",
        "        spectrogram_tensor = torch.FloatTensor(spectrogram).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
        "\n",
        "        # Concatenate along a new dimension to create a tensor with two channels\n",
        "        combined_tensor = torch.cat((spectrogram_tensor, mfccs_resized), dim=1).squeeze(0)\n",
        "\n",
        "\n",
        "        # bell = 0, diaphragm = 1, extended = 2\n",
        "        mode = 0\n",
        "        if filename.startswith(\"D\"):\n",
        "          mode = 1\n",
        "        elif filename.startswith(\"E\"):\n",
        "          mode = 2\n",
        "        if directory == \"/content/drive/MyDrive/ICBHI_final_database\":\n",
        "          mode = 1\n",
        "          diagnosis = patient_diagnosis[int(filename.split(\"_\")[0])]\n",
        "        else:\n",
        "          diagnosis = filename.split(\"_\")[1].split(\",\")[0].lower()\n",
        "\n",
        "        # Add x data row to x_data\n",
        "        #image = torch.FloatTensor(image)\n",
        "        x_data.append([combined_tensor, mode])\n",
        "\n",
        "        # Get y and add it to y_data\n",
        "        y_data.append(diagnosis)\n",
        "  return x_data, y_data\n",
        "\n",
        "#directories = [\"/content/drive/MyDrive/training audio files\", \"/content/drive/MyDrive/ICBHI_final_database\"]\n",
        "directories = [\"/content/drive/MyDrive/training audio files\"]\n",
        "x_data, y_data = preprocess(directories)\n",
        "print(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIFOsltI2igp",
        "outputId": "594f5864-10fc-4929-8dcb-2a1a49514a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['asthma' '600']\n",
            " ['bron' '42']\n",
            " ['copd' '177']\n",
            " ['heart failure' '306']\n",
            " ['lung fibrosis' '69']\n",
            " ['n' '693']\n",
            " ['plueral effusion' '57']\n",
            " ['pneumonia' '108']]\n"
          ]
        }
      ],
      "source": [
        "# Print count of y_data\n",
        "unique, counts = np.unique(y_data, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFDm_KAohJ-x",
        "outputId": "f4d97e5a-d72a-4c80-a568-be1e4feeff1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['asthma' '100']\n",
            " ['bron' '42']\n",
            " ['copd' '100']\n",
            " ['heart failure' '100']\n",
            " ['lung fibrosis' '69']\n",
            " ['n' '100']\n",
            " ['plueral effusion' '57']\n",
            " ['pneumonia' '100']]\n"
          ]
        }
      ],
      "source": [
        "# trim some data away to balance it out\n",
        "a = 0\n",
        "copd = 0\n",
        "hf = 0\n",
        "n = 0\n",
        "pn = 0\n",
        "y_data_copy = []\n",
        "x_data_copy = []\n",
        "for i in range(len(y_data)):\n",
        "  if y_data[i] == \"asthma\":\n",
        "    if a < 100:\n",
        "      a += 1\n",
        "      y_data_copy.append(y_data[i])\n",
        "      x_data_copy.append(x_data[i])\n",
        "  elif y_data[i] == \"copd\":\n",
        "    if copd < 100:\n",
        "      copd += 1\n",
        "      y_data_copy.append(y_data[i])\n",
        "      x_data_copy.append(x_data[i])\n",
        "  elif y_data[i] == \"heart failure\":\n",
        "    if hf < 100:\n",
        "      hf += 1\n",
        "      y_data_copy.append(y_data[i])\n",
        "      x_data_copy.append(x_data[i])\n",
        "  elif y_data[i] == \"n\":\n",
        "    if n < 100:\n",
        "      n += 1\n",
        "      y_data_copy.append(y_data[i])\n",
        "      x_data_copy.append(x_data[i])\n",
        "  elif y_data[i] == \"pneumonia\":\n",
        "    if pn < 100:\n",
        "      pn += 1\n",
        "      y_data_copy.append(y_data[i])\n",
        "      x_data_copy.append(x_data[i])\n",
        "  else:\n",
        "    y_data_copy.append(y_data[i])\n",
        "    x_data_copy.append(x_data[i])\n",
        "\n",
        "b = 42\n",
        "lf = 69\n",
        "pf = 57\n",
        "\n",
        "unique, counts = np.unique(y_data_copy, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqo70y7a5RYq",
        "outputId": "7cc033bb-5d85-4794-d1fc-aa634fb4faa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['asthma' '100']\n",
            " ['bron' '100']\n",
            " ['copd' '100']\n",
            " ['heart failure' '100']\n",
            " ['lung fibrosis' '100']\n",
            " ['n' '100']\n",
            " ['plueral effusion' '100']\n",
            " ['pneumonia' '100']]\n"
          ]
        }
      ],
      "source": [
        "# Sample diagnosis with less than 100 records multiple times\n",
        "for i in range(len(y_data)):\n",
        "  if y_data[i] == \"bron\":\n",
        "    if b < 100:\n",
        "      b += 1\n",
        "      y_data_copy.append(y_data[i])\n",
        "      x_data_copy.append(x_data[i])\n",
        "  elif y_data[i] == \"lung fibrosis\":\n",
        "    if lf < 100:\n",
        "      lf += 1\n",
        "      y_data_copy.append(y_data[i])\n",
        "      x_data_copy.append(x_data[i])\n",
        "  elif y_data[i] == \"plueral effusion\":\n",
        "    if pf < 100:\n",
        "      pf += 1\n",
        "      y_data_copy.append(y_data[i])\n",
        "      x_data_copy.append(x_data[i])\n",
        "\n",
        "unique, counts = np.unique(y_data_copy, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mkO-bAuj2mJ4"
      },
      "outputs": [],
      "source": [
        "# Reshape y_data for encoding\n",
        "y_data = np.array(y_data).reshape(-1, 1)\n",
        "\n",
        "# Perform one hot encoing on y_data\n",
        "enc = OneHotEncoder()\n",
        "y_data = enc.fit_transform(y_data).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2ozo5yescpyj"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x_data, y_data):\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x_data[idx]\n",
        "        y = self.y_data[idx]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jELpADHWnnW0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create datasest for train and test data\n",
        "train_ds = CustomDataset(x_train, y_train)\n",
        "test_ds = CustomDataset(x_test, y_test)\n",
        "\n",
        "# Create DataLoaders for traing and test data\n",
        "batch_size = 150\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "K-NoCfjFlSPY"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class DiagnosisNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DiagnosisNetwork, self).__init__()\n",
        "\n",
        "    self.final_output_size = 8\n",
        "    self.scalar_output_size = 32\n",
        "    self.combined_input_size = 312\n",
        "\n",
        "    self.convolution_pipeline = nn.Sequential(\n",
        "        nn.Conv2d(2, 24, kernel_size=(5, 5), stride=(4, 2), padding=0),\n",
        "        nn.BatchNorm2d(24),\n",
        "        nn.LeakyReLU(0.01),\n",
        "\n",
        "        nn.Conv2d(24, 16, kernel_size=(5, 5), stride=(1, 1), padding=0),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.LeakyReLU(0.01),\n",
        "\n",
        "        nn.MaxPool2d(kernel_size=(4, 2), stride=(4, 2)),\n",
        "\n",
        "        nn.Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=0),\n",
        "        nn.BatchNorm2d(4),\n",
        "        nn.LeakyReLU(0.01),\n",
        "        nn.Flatten(),\n",
        "    )\n",
        "\n",
        "    self.scalar_pipeline = nn.Sequential(\n",
        "        nn.Linear(1, self.scalar_output_size),\n",
        "        nn.LeakyReLU(0.01)\n",
        "    )\n",
        "\n",
        "    self.combined_pipeline = nn.Sequential(\n",
        "        nn.Linear(self.combined_input_size, 1024),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.LeakyReLU(0.01),\n",
        "        nn.Dropout(0.5),\n",
        "\n",
        "        nn.Linear(1024, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.LeakyReLU(0.01),\n",
        "        nn.Dropout(0.5),\n",
        "\n",
        "        nn.Linear(512, 128),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.LeakyReLU(0.01),\n",
        "        nn.Dropout(0.5),\n",
        "\n",
        "        nn.Linear(128, 64),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.LeakyReLU(0.01),\n",
        "        nn.Dropout(0.5),\n",
        "\n",
        "        nn.Linear(64, self.final_output_size),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "\n",
        "    # Combine features from both inputs\n",
        "    #self.combine_layer = nn.Linear(64 + 32, self.output_size)  # Adjust the output size as needed\n",
        "\n",
        "  def forward(self, input_2d_array, input_scalar):\n",
        "\n",
        "    # Process 2D array input with convolution\n",
        "    conv_flat = self.convolution_pipeline(input_2d_array)\n",
        "    #final_output = self.no_mode_post_convolution(conv_flat)\n",
        "\n",
        "    # Process scalar input\n",
        "    scalar_output = self.scalar_pipeline(input_scalar)\n",
        "\n",
        "    # Concatenate the outputs of both branches\n",
        "    combined_output = torch.cat((conv_flat, scalar_output), dim=1)\n",
        "\n",
        "    # Final output layer\n",
        "    final_output = self.combined_pipeline(combined_output)\n",
        "\n",
        "    return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL1NPYT4lSop",
        "outputId": "758706eb-8093-4b8c-8009-42bacdb31991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Epoch: 0, Loss: 2.0418348227832332\n",
            "Epoch: 1, Loss: 1.9875117988451152\n",
            "Epoch: 2, Loss: 1.9487256936147703\n",
            "Epoch: 3, Loss: 1.9145009179487296\n",
            "Epoch: 4, Loss: 1.8454225435324594\n",
            "Epoch: 5, Loss: 1.8689013110830428\n",
            "Epoch: 6, Loss: 1.8290561471425049\n",
            "Epoch: 7, Loss: 1.8750972020710612\n",
            "Epoch: 8, Loss: 1.8105671202882807\n",
            "Epoch: 9, Loss: 1.842444508633715\n",
            "Epoch: 10, Loss: 1.8132747276454952\n",
            "Epoch: 11, Loss: 1.7994715372721353\n",
            "Epoch: 12, Loss: 1.7990430551217802\n",
            "Epoch: 13, Loss: 1.7819863718452182\n",
            "Epoch: 14, Loss: 1.7914985739592963\n",
            "Epoch: 15, Loss: 1.7434158984650956\n",
            "Epoch: 16, Loss: 1.7528099489550217\n",
            "Epoch: 17, Loss: 1.8191724525275805\n",
            "Epoch: 18, Loss: 1.8024399145275143\n",
            "Epoch: 19, Loss: 1.7044734371469374\n",
            "Epoch: 20, Loss: 1.7402292388550777\n",
            "Epoch: 21, Loss: 1.6672139108603727\n",
            "Epoch: 22, Loss: 1.7063651160990938\n",
            "Epoch: 23, Loss: 1.697219764087217\n",
            "Epoch: 24, Loss: 1.6837073048801285\n",
            "Epoch: 25, Loss: 1.5863381953949625\n",
            "Epoch: 26, Loss: 1.6330778784785709\n",
            "Epoch: 27, Loss: 1.6475078002780887\n",
            "Epoch: 28, Loss: 1.6897566487603153\n",
            "Epoch: 29, Loss: 1.638441027478969\n",
            "Epoch: 30, Loss: 1.6148500746869026\n",
            "Epoch: 31, Loss: 1.603309802129759\n",
            "Epoch: 32, Loss: 1.6104360801953796\n",
            "Epoch: 33, Loss: 1.6057267468026344\n",
            "Epoch: 34, Loss: 1.5320534291842305\n",
            "Epoch: 35, Loss: 1.6117864855637787\n",
            "Epoch: 36, Loss: 1.5554380932598248\n",
            "Epoch: 37, Loss: 1.6332621532129057\n",
            "Epoch: 38, Loss: 1.5774119720391349\n",
            "Epoch: 39, Loss: 1.5671772263574262\n",
            "Epoch: 40, Loss: 1.5782477390681597\n",
            "Epoch: 41, Loss: 1.5975340444145474\n",
            "Epoch: 42, Loss: 1.5401528836987541\n",
            "Epoch: 43, Loss: 1.552302232025363\n",
            "Epoch: 44, Loss: 1.5106570255671832\n",
            "Epoch: 45, Loss: 1.5072330599980996\n",
            "Epoch: 46, Loss: 1.5591315961053185\n",
            "Epoch: 47, Loss: 1.5188139042955764\n",
            "Epoch: 48, Loss: 1.5311442977147744\n",
            "Epoch: 49, Loss: 1.4936619506660083\n",
            "Epoch: 50, Loss: 1.557674172922229\n",
            "Epoch: 51, Loss: 1.518998403921195\n",
            "Epoch: 52, Loss: 1.5430009610264013\n",
            "Epoch: 53, Loss: 1.5665829452217048\n",
            "Epoch: 54, Loss: 1.4907909969911508\n",
            "Epoch: 55, Loss: 1.593586467682047\n",
            "Epoch: 56, Loss: 1.5426832927879712\n",
            "Epoch: 57, Loss: 1.4380564757272707\n",
            "Epoch: 58, Loss: 1.584394747483815\n",
            "Epoch: 59, Loss: 1.596411592571448\n",
            "Epoch: 60, Loss: 1.5915823202606634\n",
            "Epoch: 61, Loss: 1.503669597578387\n",
            "Epoch: 62, Loss: 1.5434988001559642\n",
            "Epoch: 63, Loss: 1.5327183802922566\n",
            "Epoch: 64, Loss: 1.490745095496482\n",
            "Epoch: 65, Loss: 1.509017142843693\n",
            "Epoch: 66, Loss: 1.4391931312304016\n",
            "Epoch: 67, Loss: 1.5320589246479333\n",
            "Epoch: 68, Loss: 1.511839213100731\n",
            "Epoch: 69, Loss: 1.483602372467095\n",
            "Epoch: 70, Loss: 1.530989186138126\n",
            "Epoch: 71, Loss: 1.4867731552597478\n",
            "Epoch: 72, Loss: 1.4797502054390332\n",
            "Epoch: 73, Loss: 1.5342353007472154\n",
            "Epoch: 74, Loss: 1.4795712756772412\n",
            "Epoch: 75, Loss: 1.5231730143229167\n",
            "Epoch: 76, Loss: 1.5276390948194138\n",
            "Epoch: 77, Loss: 1.5456739478077448\n",
            "Epoch: 78, Loss: 1.5695639645799677\n",
            "Epoch: 79, Loss: 1.4730239506308913\n",
            "Epoch: 80, Loss: 1.521652935244513\n",
            "Epoch: 81, Loss: 1.46282142104832\n",
            "Epoch: 82, Loss: 1.510234329717379\n",
            "Epoch: 83, Loss: 1.5672141939190263\n",
            "Epoch: 84, Loss: 1.5054246390119512\n",
            "Epoch: 85, Loss: 1.5742747284841876\n",
            "Epoch: 86, Loss: 1.5182979267539707\n",
            "Epoch: 87, Loss: 1.5084379480240193\n",
            "Epoch: 88, Loss: 1.4979724807942167\n",
            "Epoch: 89, Loss: 1.604808471727033\n",
            "Epoch: 90, Loss: 1.4844403359906893\n",
            "Epoch: 91, Loss: 1.4729929452246808\n",
            "Epoch: 92, Loss: 1.544725401181701\n",
            "Epoch: 93, Loss: 1.501123880663662\n",
            "Epoch: 94, Loss: 1.5436156396324752\n",
            "Epoch: 95, Loss: 1.536170610299347\n",
            "Epoch: 96, Loss: 1.5562807558276128\n",
            "Epoch: 97, Loss: 1.5217326101681865\n",
            "Epoch: 98, Loss: 1.5410008109207693\n",
            "Epoch: 99, Loss: 1.5070192856146087\n",
            "Epoch: 100, Loss: 1.4708511778648863\n",
            "Epoch: 101, Loss: 1.444432463206298\n",
            "Epoch: 102, Loss: 1.5143355139603851\n",
            "Epoch: 103, Loss: 1.5354807165497584\n",
            "Epoch: 104, Loss: 1.4805759681877515\n",
            "Epoch: 105, Loss: 1.5169507349636537\n",
            "Epoch: 106, Loss: 1.5034809112548828\n",
            "Epoch: 107, Loss: 1.4993084542294766\n",
            "Epoch: 108, Loss: 1.486949286562331\n",
            "Epoch: 109, Loss: 1.4764119775582711\n",
            "Epoch: 110, Loss: 1.4718959407603487\n",
            "Epoch: 111, Loss: 1.475471904937257\n",
            "Epoch: 112, Loss: 1.523656277791828\n",
            "Epoch: 113, Loss: 1.5383270776018183\n",
            "Epoch: 114, Loss: 1.537638413145187\n",
            "Epoch: 115, Loss: 1.4921065991651927\n",
            "Epoch: 116, Loss: 1.496131604444896\n",
            "Epoch: 117, Loss: 1.492537797765529\n",
            "Epoch: 118, Loss: 1.4724177392661995\n",
            "Epoch: 119, Loss: 1.4801521842361343\n",
            "Epoch: 120, Loss: 1.442102388287267\n",
            "Epoch: 121, Loss: 1.4847789436367387\n",
            "Epoch: 122, Loss: 1.4937459746151105\n",
            "Epoch: 123, Loss: 1.4629998173274046\n",
            "Epoch: 124, Loss: 1.4839176565197343\n",
            "Epoch: 125, Loss: 1.455419491368828\n",
            "Epoch: 126, Loss: 1.4595180749893188\n",
            "Epoch: 127, Loss: 1.4670586256270712\n",
            "Epoch: 128, Loss: 1.4636495045736326\n",
            "Epoch: 129, Loss: 1.4837022005243503\n",
            "Epoch: 130, Loss: 1.471292384972809\n",
            "Epoch: 131, Loss: 1.4242460837600923\n",
            "Epoch: 132, Loss: 1.4323467591130141\n",
            "Epoch: 133, Loss: 1.4369542531087889\n",
            "Epoch: 134, Loss: 1.4657411955772561\n",
            "Epoch: 135, Loss: 1.4737025287979884\n",
            "Epoch: 136, Loss: 1.4516819047589673\n",
            "Epoch: 137, Loss: 1.4749848884893646\n",
            "Epoch: 138, Loss: 1.4592348869810712\n",
            "Epoch: 139, Loss: 1.4643476525097028\n",
            "Epoch: 140, Loss: 1.450668937771033\n",
            "Epoch: 141, Loss: 1.4228413865921345\n",
            "Epoch: 142, Loss: 1.4343553671600124\n",
            "Epoch: 143, Loss: 1.4450001572886257\n",
            "Epoch: 144, Loss: 1.4573934610853803\n",
            "Epoch: 145, Loss: 1.4660468659502395\n",
            "Epoch: 146, Loss: 1.3817873212462621\n",
            "Epoch: 147, Loss: 1.455891561000905\n",
            "Epoch: 148, Loss: 1.4066787180325664\n",
            "Epoch: 149, Loss: 1.4102435568545726\n",
            "Epoch: 150, Loss: 1.4445727886037623\n",
            "Epoch: 151, Loss: 1.3892405159929966\n",
            "Epoch: 152, Loss: 1.4227352074697508\n",
            "Epoch: 153, Loss: 1.4551923706176433\n",
            "Epoch: 154, Loss: 1.4538145065307617\n",
            "Epoch: 155, Loss: 1.4137578805287678\n",
            "Epoch: 156, Loss: 1.4643051463661465\n",
            "Epoch: 157, Loss: 1.3928700169772965\n",
            "Epoch: 158, Loss: 1.4246915553478483\n",
            "Epoch: 159, Loss: 1.4006697150832372\n",
            "Epoch: 160, Loss: 1.4385451289778906\n",
            "Epoch: 161, Loss: 1.4224873561385676\n",
            "Epoch: 162, Loss: 1.478125256849519\n",
            "Epoch: 163, Loss: 1.4259907184763156\n",
            "Epoch: 164, Loss: 1.4015284573778193\n",
            "Epoch: 165, Loss: 1.4545219637823443\n",
            "Epoch: 166, Loss: 1.3884144116800727\n",
            "Epoch: 167, Loss: 1.463843748079124\n",
            "Epoch: 168, Loss: 1.4784918321785352\n",
            "Epoch: 169, Loss: 1.4185991862141494\n",
            "Epoch: 170, Loss: 1.3869605191210483\n",
            "Epoch: 171, Loss: 1.46089620454937\n",
            "Epoch: 172, Loss: 1.4428885676336627\n",
            "Epoch: 173, Loss: 1.459536335992475\n",
            "Epoch: 174, Loss: 1.4746360990172582\n",
            "Epoch: 175, Loss: 1.4396847850042032\n",
            "Epoch: 176, Loss: 1.3979606476235897\n",
            "Epoch: 177, Loss: 1.503058118177644\n",
            "Epoch: 178, Loss: 1.4470983380121543\n",
            "Epoch: 179, Loss: 1.3881881127120754\n",
            "Epoch: 180, Loss: 1.4726873509427334\n",
            "Epoch: 181, Loss: 1.417878121348983\n",
            "Epoch: 182, Loss: 1.4534140732271452\n",
            "Epoch: 183, Loss: 1.4433835186856858\n",
            "Epoch: 184, Loss: 1.451642446484126\n",
            "Epoch: 185, Loss: 1.4382197138265516\n",
            "Epoch: 186, Loss: 1.4257701525451443\n",
            "Epoch: 187, Loss: 1.4012883969232546\n",
            "Epoch: 188, Loss: 1.4396389443823632\n",
            "Epoch: 189, Loss: 1.422254537014251\n",
            "Epoch: 190, Loss: 1.3725276001801727\n",
            "Epoch: 191, Loss: 1.4608623550293294\n",
            "Epoch: 192, Loss: 1.3985825886963106\n",
            "Epoch: 193, Loss: 1.4364067231509703\n",
            "Epoch: 194, Loss: 1.4258164598586711\n",
            "Epoch: 195, Loss: 1.4083154226871246\n",
            "Epoch: 196, Loss: 1.4074501171179696\n",
            "Epoch: 197, Loss: 1.3988847318270528\n",
            "Epoch: 198, Loss: 1.3933719278227352\n",
            "Epoch: 199, Loss: 1.4317657930631165\n",
            "Epoch: 200, Loss: 1.4093471249790055\n",
            "Epoch: 201, Loss: 1.4043635045382994\n",
            "Epoch: 202, Loss: 1.386778358872055\n",
            "Epoch: 203, Loss: 1.3843617456179138\n",
            "Epoch: 204, Loss: 1.373187963844191\n",
            "Epoch: 205, Loss: 1.394082285833697\n",
            "Epoch: 206, Loss: 1.4285873749577407\n",
            "Epoch: 207, Loss: 1.4020130431398432\n",
            "Epoch: 208, Loss: 1.4163453130857317\n",
            "Epoch: 209, Loss: 1.3805925381099078\n",
            "Epoch: 210, Loss: 1.3498682020403814\n",
            "Epoch: 211, Loss: 1.399391531944275\n",
            "Epoch: 212, Loss: 1.4057784021323454\n",
            "Epoch: 213, Loss: 1.3879740838463424\n",
            "Epoch: 214, Loss: 1.441855046766024\n",
            "Epoch: 215, Loss: 1.3717120699848688\n",
            "Epoch: 216, Loss: 1.4071394306548097\n",
            "Epoch: 217, Loss: 1.3759231499746336\n",
            "Epoch: 218, Loss: 1.3618265102941094\n",
            "Epoch: 219, Loss: 1.4252905177731885\n",
            "Epoch: 220, Loss: 1.3603670630894653\n",
            "Epoch: 221, Loss: 1.4286945525636063\n",
            "Epoch: 222, Loss: 1.3969354621062042\n",
            "Epoch: 223, Loss: 1.3713844752480797\n",
            "Epoch: 224, Loss: 1.331471582676502\n",
            "Epoch: 225, Loss: 1.3941253246145044\n",
            "Epoch: 226, Loss: 1.377565213974486\n",
            "Epoch: 227, Loss: 1.3774229651647256\n",
            "Epoch: 228, Loss: 1.3925627884289897\n",
            "Epoch: 229, Loss: 1.3943791862920667\n",
            "Epoch: 230, Loss: 1.3831825695984752\n",
            "Epoch: 231, Loss: 1.3712102166304352\n",
            "Epoch: 232, Loss: 1.3602693512084636\n",
            "Epoch: 233, Loss: 1.397466020381197\n",
            "Epoch: 234, Loss: 1.3716338069726388\n",
            "Epoch: 235, Loss: 1.4011094663160066\n",
            "Epoch: 236, Loss: 1.4131251565108063\n",
            "Epoch: 237, Loss: 1.3780906876773698\n",
            "Epoch: 238, Loss: 1.4249194759003658\n",
            "Epoch: 239, Loss: 1.4080852625217843\n",
            "Epoch: 240, Loss: 1.3863560899775078\n",
            "Epoch: 241, Loss: 1.407560942020822\n",
            "Epoch: 242, Loss: 1.3608014431405575\n",
            "Epoch: 243, Loss: 1.4002793629964192\n",
            "Epoch: 244, Loss: 1.310153584953741\n",
            "Epoch: 245, Loss: 1.3904076662469418\n",
            "Epoch: 246, Loss: 1.3723681378871837\n",
            "Epoch: 247, Loss: 1.3883361292223557\n",
            "Epoch: 248, Loss: 1.3875308670896165\n",
            "Epoch: 249, Loss: 1.3875809620458184\n",
            "Epoch: 250, Loss: 1.3770390486886315\n",
            "Epoch: 251, Loss: 1.3766654095751174\n",
            "Epoch: 252, Loss: 1.371315450533062\n",
            "Epoch: 253, Loss: 1.3859407521308735\n",
            "Epoch: 254, Loss: 1.3748875366035083\n",
            "Epoch: 255, Loss: 1.4300483811831644\n",
            "Epoch: 256, Loss: 1.4016553256528597\n",
            "Epoch: 257, Loss: 1.3627381113404078\n",
            "Epoch: 258, Loss: 1.3674653438811606\n",
            "Epoch: 259, Loss: 1.3446226204540712\n",
            "Epoch: 260, Loss: 1.3741440468646111\n",
            "Epoch: 261, Loss: 1.3919358786116254\n",
            "Epoch: 262, Loss: 1.4182689401274877\n",
            "Epoch: 263, Loss: 1.3904756544329595\n",
            "Epoch: 264, Loss: 1.3422531362966443\n",
            "Epoch: 265, Loss: 1.4004472105215626\n",
            "Epoch: 266, Loss: 1.3816834307731465\n",
            "Epoch: 267, Loss: 1.4019056600881805\n",
            "Epoch: 268, Loss: 1.4180404455103772\n",
            "Epoch: 269, Loss: 1.4157782945227115\n",
            "Epoch: 270, Loss: 1.388684738612344\n",
            "Epoch: 271, Loss: 1.365787073230067\n",
            "Epoch: 272, Loss: 1.3302224806859984\n",
            "Epoch: 273, Loss: 1.3366891948889332\n",
            "Epoch: 274, Loss: 1.4246317317299808\n",
            "Epoch: 275, Loss: 1.3679337881981057\n",
            "Epoch: 276, Loss: 1.3415264220947916\n",
            "Epoch: 277, Loss: 1.3618504299339673\n",
            "Epoch: 278, Loss: 1.4352979550124905\n",
            "Epoch: 279, Loss: 1.383410945851752\n",
            "Epoch: 280, Loss: 1.366044375067907\n",
            "Epoch: 281, Loss: 1.3612584306838664\n",
            "Epoch: 282, Loss: 1.3873408500184403\n",
            "Epoch: 283, Loss: 1.3455612448090357\n",
            "Epoch: 284, Loss: 1.4184738913326398\n",
            "Epoch: 285, Loss: 1.3497732793185728\n",
            "Epoch: 286, Loss: 1.3882947678261615\n",
            "Epoch: 287, Loss: 1.3685546208780708\n",
            "Epoch: 288, Loss: 1.3777928056446374\n",
            "Epoch: 289, Loss: 1.3692182133383783\n",
            "Epoch: 290, Loss: 1.3808634822250259\n",
            "Epoch: 291, Loss: 1.399698333537325\n",
            "Epoch: 292, Loss: 1.380912905043744\n",
            "Epoch: 293, Loss: 1.3540018560193108\n",
            "Epoch: 294, Loss: 1.3476406707831308\n",
            "Epoch: 295, Loss: 1.3468162912003536\n",
            "Epoch: 296, Loss: 1.3595229894556897\n",
            "Epoch: 297, Loss: 1.3600072945263368\n",
            "Epoch: 298, Loss: 1.3428398666652381\n",
            "Epoch: 299, Loss: 1.3533743755191776\n",
            "Epoch: 300, Loss: 1.3695281879276249\n",
            "Epoch: 301, Loss: 1.3528744185224493\n",
            "Epoch: 302, Loss: 1.4024494539761374\n",
            "Epoch: 303, Loss: 1.380724326093146\n",
            "Epoch: 304, Loss: 1.3854631075622341\n",
            "Epoch: 305, Loss: 1.3504429768163262\n",
            "Epoch: 306, Loss: 1.3839748539823167\n",
            "Epoch: 307, Loss: 1.37497929478368\n",
            "Epoch: 308, Loss: 1.3876495192236933\n",
            "Epoch: 309, Loss: 1.3599167833936976\n",
            "Epoch: 310, Loss: 1.3723464045964233\n",
            "Epoch: 311, Loss: 1.3772631131165416\n",
            "Epoch: 312, Loss: 1.416216995699186\n",
            "Epoch: 313, Loss: 1.3243814909711797\n",
            "Epoch: 314, Loss: 1.4036910601541506\n",
            "Epoch: 315, Loss: 1.3728517412293888\n",
            "Epoch: 316, Loss: 1.382768247989898\n",
            "Epoch: 317, Loss: 1.4153230376277408\n",
            "Epoch: 318, Loss: 1.353368212990727\n",
            "Epoch: 319, Loss: 1.337879864036614\n",
            "Epoch: 320, Loss: 1.38014211215026\n",
            "Epoch: 321, Loss: 1.380423166227679\n",
            "Epoch: 322, Loss: 1.3626444238297482\n",
            "Epoch: 323, Loss: 1.3986623777565381\n",
            "Epoch: 324, Loss: 1.390676477276687\n",
            "Epoch: 325, Loss: 1.347291981074827\n",
            "Epoch: 326, Loss: 1.3673002390151328\n",
            "Epoch: 327, Loss: 1.3749609145712345\n",
            "Epoch: 328, Loss: 1.3508699988642483\n",
            "Epoch: 329, Loss: 1.3956022347118837\n",
            "Epoch: 330, Loss: 1.3660006861314706\n",
            "Epoch: 331, Loss: 1.3468209555808535\n",
            "Epoch: 332, Loss: 1.3548339918150123\n",
            "Epoch: 333, Loss: 1.3790515881058172\n",
            "Epoch: 334, Loss: 1.3643775324449472\n",
            "Epoch: 335, Loss: 1.4055371850940352\n",
            "Epoch: 336, Loss: 1.3661850310386494\n",
            "Epoch: 337, Loss: 1.3661017045907096\n",
            "Epoch: 338, Loss: 1.3404027054495844\n",
            "Epoch: 339, Loss: 1.3927253586180666\n",
            "Epoch: 340, Loss: 1.4062309856955886\n",
            "Epoch: 341, Loss: 1.4227429628372192\n",
            "Epoch: 342, Loss: 1.3460676298073844\n",
            "Epoch: 343, Loss: 1.3587145602449457\n",
            "Epoch: 344, Loss: 1.3614541165372158\n",
            "Epoch: 345, Loss: 1.353190358648909\n",
            "Epoch: 346, Loss: 1.3738645839352979\n",
            "Epoch: 347, Loss: 1.3500029186830453\n",
            "Epoch: 348, Loss: 1.3663014858327014\n",
            "Epoch: 349, Loss: 1.3546855940040967\n",
            "Epoch: 350, Loss: 1.3462887900940914\n",
            "Epoch: 351, Loss: 1.3349907085405173\n",
            "Epoch: 352, Loss: 1.3490146466180788\n",
            "Epoch: 353, Loss: 1.3639183061342712\n",
            "Epoch: 354, Loss: 1.3683605929638476\n",
            "Epoch: 355, Loss: 1.3608232660496489\n",
            "Epoch: 356, Loss: 1.38136026368919\n",
            "Epoch: 357, Loss: 1.3286242645683017\n",
            "Epoch: 358, Loss: 1.3553177270483463\n",
            "Epoch: 359, Loss: 1.3681611346860303\n",
            "Epoch: 360, Loss: 1.3518674872445722\n",
            "Epoch: 361, Loss: 1.324094607474956\n",
            "Epoch: 362, Loss: 1.3603861416485292\n",
            "Epoch: 363, Loss: 1.347203772118751\n",
            "Epoch: 364, Loss: 1.3358075813198766\n",
            "Epoch: 365, Loss: 1.3367875340982531\n",
            "Epoch: 366, Loss: 1.351592128158461\n",
            "Epoch: 367, Loss: 1.334816073694973\n",
            "Epoch: 368, Loss: 1.3788035203379096\n",
            "Epoch: 369, Loss: 1.3572242615070749\n",
            "Epoch: 370, Loss: 1.3482726144452466\n",
            "Epoch: 371, Loss: 1.368129845206619\n",
            "Epoch: 372, Loss: 1.3397848639927856\n",
            "Epoch: 373, Loss: 1.325401263879546\n",
            "Epoch: 374, Loss: 1.3156524685257716\n",
            "Epoch: 375, Loss: 1.3325748020875539\n",
            "Epoch: 376, Loss: 1.332103668375218\n",
            "Epoch: 377, Loss: 1.3432008264758062\n",
            "Epoch: 378, Loss: 1.3505317615279069\n",
            "Epoch: 379, Loss: 1.3112754018594186\n",
            "Epoch: 380, Loss: 1.3474395807753217\n",
            "Epoch: 381, Loss: 1.357554923558066\n",
            "Epoch: 382, Loss: 1.3472096531103688\n",
            "Epoch: 383, Loss: 1.3171716953845733\n",
            "Epoch: 384, Loss: 1.327754222754891\n",
            "Epoch: 385, Loss: 1.3196667551148868\n",
            "Epoch: 386, Loss: 1.3341912420083444\n",
            "Epoch: 387, Loss: 1.3956329788722044\n",
            "Epoch: 388, Loss: 1.3278743764187426\n",
            "Epoch: 389, Loss: 1.3264614732552926\n",
            "Epoch: 390, Loss: 1.3575396098143666\n",
            "Epoch: 391, Loss: 1.3158763283533408\n",
            "Epoch: 392, Loss: 1.3472261318923733\n",
            "Epoch: 393, Loss: 1.3557630278539996\n",
            "Epoch: 394, Loss: 1.3393391074863732\n",
            "Epoch: 395, Loss: 1.3735398104850283\n",
            "Epoch: 396, Loss: 1.3580388329553266\n",
            "Epoch: 397, Loss: 1.3178436088223828\n",
            "Epoch: 398, Loss: 1.3471591007624957\n",
            "Epoch: 399, Loss: 1.3251976882312315\n",
            "Epoch: 400, Loss: 1.3380203534525337\n",
            "Epoch: 401, Loss: 1.3201086664876194\n",
            "Epoch: 402, Loss: 1.3879673759988014\n",
            "Epoch: 403, Loss: 1.3627865796393537\n",
            "Epoch: 404, Loss: 1.332648606165081\n",
            "Epoch: 405, Loss: 1.3611598226195532\n",
            "Epoch: 406, Loss: 1.3491913942580527\n",
            "Epoch: 407, Loss: 1.3525656859079997\n",
            "Epoch: 408, Loss: 1.3432314691814125\n",
            "Epoch: 409, Loss: 1.3521175578976354\n",
            "Epoch: 410, Loss: 1.3335652148469965\n",
            "Epoch: 411, Loss: 1.3413587123789685\n",
            "Epoch: 412, Loss: 1.3350701078455498\n",
            "Epoch: 413, Loss: 1.3389281567106854\n",
            "Epoch: 414, Loss: 1.3330050875954593\n",
            "Epoch: 415, Loss: 1.3626147001347644\n",
            "Epoch: 416, Loss: 1.362986831800312\n",
            "Epoch: 417, Loss: 1.3468827634838456\n",
            "Epoch: 418, Loss: 1.3468639706888943\n",
            "Epoch: 419, Loss: 1.3705156060820776\n",
            "Epoch: 420, Loss: 1.3483407353678494\n",
            "Epoch: 421, Loss: 1.3398942938933136\n",
            "Epoch: 422, Loss: 1.3340186379480024\n",
            "Epoch: 423, Loss: 1.3558320314326184\n",
            "Epoch: 424, Loss: 1.338070789127485\n",
            "Epoch: 425, Loss: 1.3526019339865827\n",
            "Epoch: 426, Loss: 1.312801036428898\n",
            "Epoch: 427, Loss: 1.3363671708614269\n",
            "Epoch: 428, Loss: 1.3410578602594687\n",
            "Epoch: 429, Loss: 1.3561712182159964\n",
            "Epoch: 430, Loss: 1.3561927967883172\n",
            "Epoch: 431, Loss: 1.3604283772461803\n",
            "Epoch: 432, Loss: 1.352142238447852\n",
            "Epoch: 433, Loss: 1.333955392769888\n",
            "Epoch: 434, Loss: 1.332441375610676\n",
            "Epoch: 435, Loss: 1.3164136866305736\n",
            "Epoch: 436, Loss: 1.3446042622234804\n",
            "Epoch: 437, Loss: 1.3395351518130472\n",
            "Epoch: 438, Loss: 1.3494142395384767\n",
            "Epoch: 439, Loss: 1.3523078142328464\n",
            "Epoch: 440, Loss: 1.3309179324630305\n",
            "Epoch: 441, Loss: 1.3573653452785301\n",
            "Epoch: 442, Loss: 1.3601922227981242\n",
            "Epoch: 443, Loss: 1.3392162500543796\n",
            "Epoch: 444, Loss: 1.3674808233342273\n",
            "Epoch: 445, Loss: 1.3039045207043911\n",
            "Epoch: 446, Loss: 1.3031438893460212\n",
            "Epoch: 447, Loss: 1.3315982074602275\n",
            "Epoch: 448, Loss: 1.3187775780968631\n",
            "Epoch: 449, Loss: 1.3238750045181167\n",
            "Epoch: 450, Loss: 1.3675533922006051\n",
            "Epoch: 451, Loss: 1.3053340252409589\n",
            "Epoch: 452, Loss: 1.3435800988623436\n",
            "Epoch: 453, Loss: 1.3557363748550415\n",
            "Epoch: 454, Loss: 1.316501538804237\n",
            "Epoch: 455, Loss: 1.3265610358393785\n",
            "Epoch: 456, Loss: 1.3516533391695496\n",
            "Epoch: 457, Loss: 1.3466666497237294\n",
            "Epoch: 458, Loss: 1.351777748858675\n",
            "Epoch: 459, Loss: 1.309508425124148\n",
            "Epoch: 460, Loss: 1.3691384099053998\n",
            "Epoch: 461, Loss: 1.3437158013066501\n",
            "Epoch: 462, Loss: 1.3893308343616784\n",
            "Epoch: 463, Loss: 1.3369073850888733\n",
            "Epoch: 464, Loss: 1.3417647383737226\n",
            "Epoch: 465, Loss: 1.2950999423967184\n",
            "Epoch: 466, Loss: 1.3166431171674255\n",
            "Epoch: 467, Loss: 1.3595291097113427\n",
            "Epoch: 468, Loss: 1.3661589351951653\n",
            "Epoch: 469, Loss: 1.3034269691359066\n",
            "Epoch: 470, Loss: 1.3418387157697205\n",
            "Epoch: 471, Loss: 1.3393805060826294\n",
            "Epoch: 472, Loss: 1.3662461896314688\n",
            "Epoch: 473, Loss: 1.3257540481310364\n",
            "Epoch: 474, Loss: 1.3184124493429847\n",
            "Epoch: 475, Loss: 1.3182226580085483\n",
            "Epoch: 476, Loss: 1.3248921421402735\n",
            "Epoch: 477, Loss: 1.3497922073864768\n",
            "Epoch: 478, Loss: 1.324822024250707\n",
            "Epoch: 479, Loss: 1.3331282984280417\n",
            "Epoch: 480, Loss: 1.3333489683502955\n",
            "Epoch: 481, Loss: 1.3747526677787727\n",
            "Epoch: 482, Loss: 1.3320480213097647\n",
            "Epoch: 483, Loss: 1.3168521569975724\n",
            "Epoch: 484, Loss: 1.337270309739079\n",
            "Epoch: 485, Loss: 1.3296628091352205\n",
            "Epoch: 486, Loss: 1.33700045879851\n",
            "Epoch: 487, Loss: 1.3507830589375598\n",
            "Epoch: 488, Loss: 1.3693242318241308\n",
            "Epoch: 489, Loss: 1.33200045764869\n",
            "Epoch: 490, Loss: 1.3374679325320196\n",
            "Epoch: 491, Loss: 1.331274595666439\n",
            "Epoch: 492, Loss: 1.35930627457639\n",
            "Epoch: 493, Loss: 1.3166792156003044\n",
            "Epoch: 494, Loss: 1.332560029435665\n",
            "Epoch: 495, Loss: 1.373779588557304\n",
            "Epoch: 496, Loss: 1.3395897082403196\n",
            "Epoch: 497, Loss: 1.3356308632708611\n",
            "Epoch: 498, Loss: 1.3175706203947675\n",
            "Epoch: 499, Loss: 1.3243872772717307\n",
            "Epoch: 500, Loss: 1.378532128976592\n",
            "Epoch: 501, Loss: 1.3378952758532043\n",
            "Epoch: 502, Loss: 1.3092402904591662\n",
            "Epoch: 503, Loss: 1.3444862238904263\n",
            "Epoch: 504, Loss: 1.3296342876786036\n",
            "Epoch: 505, Loss: 1.323728191937115\n",
            "Epoch: 506, Loss: 1.316417027872505\n",
            "Epoch: 507, Loss: 1.3325695239060313\n",
            "Epoch: 508, Loss: 1.3623371597722913\n",
            "Epoch: 509, Loss: 1.3232193728710742\n",
            "Epoch: 510, Loss: 1.34495883545977\n",
            "Epoch: 511, Loss: 1.3534517694026866\n",
            "Epoch: 512, Loss: 1.3492311619697732\n",
            "Epoch: 513, Loss: 1.3201957957964416\n",
            "Epoch: 514, Loss: 1.3005149871745008\n",
            "Epoch: 515, Loss: 1.344563511246485\n",
            "Epoch: 516, Loss: 1.3626179627492918\n",
            "Epoch: 517, Loss: 1.3372856801283275\n",
            "Epoch: 518, Loss: 1.3394704296233806\n",
            "Epoch: 519, Loss: 1.3150339693042403\n",
            "Epoch: 520, Loss: 1.3306435557967382\n",
            "Epoch: 521, Loss: 1.3419888611380935\n",
            "Epoch: 522, Loss: 1.3633548088953005\n",
            "Epoch: 523, Loss: 1.3047359260261482\n",
            "Epoch: 524, Loss: 1.3629250932247081\n",
            "Epoch: 525, Loss: 1.3184468585548672\n",
            "Epoch: 526, Loss: 1.338002770505053\n",
            "Epoch: 527, Loss: 1.3161475565416594\n",
            "Epoch: 528, Loss: 1.3350027622060572\n",
            "Epoch: 529, Loss: 1.3189459117591804\n",
            "Epoch: 530, Loss: 1.3804493956532038\n",
            "Epoch: 531, Loss: 1.3542254385373271\n",
            "Epoch: 532, Loss: 1.338039772730347\n",
            "Epoch: 533, Loss: 1.3318914826034653\n",
            "Epoch: 534, Loss: 1.327754719037536\n",
            "Epoch: 535, Loss: 1.3461229843450775\n",
            "Epoch: 536, Loss: 1.3193330798588745\n",
            "Epoch: 537, Loss: 1.3356577487702066\n",
            "Epoch: 538, Loss: 1.3034702945262828\n",
            "Epoch: 539, Loss: 1.3221603445972956\n",
            "Epoch: 540, Loss: 1.3184363647555628\n",
            "Epoch: 541, Loss: 1.3459622716227322\n",
            "Epoch: 542, Loss: 1.3504946460115148\n",
            "Epoch: 543, Loss: 1.3058315650791141\n",
            "Epoch: 544, Loss: 1.308303510889094\n",
            "Epoch: 545, Loss: 1.2927996148454381\n",
            "Epoch: 546, Loss: 1.3085001969168373\n",
            "Epoch: 547, Loss: 1.34301902216377\n",
            "Epoch: 548, Loss: 1.3242309989658654\n",
            "Epoch: 549, Loss: 1.3396796013446564\n",
            "Epoch: 550, Loss: 1.3661338403715308\n",
            "Epoch: 551, Loss: 1.3284862853111103\n",
            "Epoch: 552, Loss: 1.3362710822558572\n",
            "Epoch: 553, Loss: 1.3378649417390214\n",
            "Epoch: 554, Loss: 1.3311195128352928\n",
            "Epoch: 555, Loss: 1.3029639788553224\n",
            "Epoch: 556, Loss: 1.2963042284579986\n",
            "Epoch: 557, Loss: 1.316171958936867\n",
            "Epoch: 558, Loss: 1.3249523605860716\n",
            "Epoch: 559, Loss: 1.3128926483451897\n",
            "Epoch: 560, Loss: 1.331368552032092\n",
            "Epoch: 561, Loss: 1.3246023663392303\n",
            "Epoch: 562, Loss: 1.3235845286795433\n",
            "Epoch: 563, Loss: 1.3090723008974223\n",
            "Epoch: 564, Loss: 1.3185228557451396\n",
            "Epoch: 565, Loss: 1.312548187607569\n",
            "Epoch: 566, Loss: 1.2900597338980817\n",
            "Epoch: 567, Loss: 1.2966715731519334\n",
            "Epoch: 568, Loss: 1.3194399810006432\n",
            "Epoch: 569, Loss: 1.3008373781298914\n",
            "Epoch: 570, Loss: 1.3193619580979044\n",
            "Epoch: 571, Loss: 1.3288632876484106\n",
            "Epoch: 572, Loss: 1.306837649210125\n",
            "Epoch: 573, Loss: 1.3114917151471401\n",
            "Epoch: 574, Loss: 1.3160375686402017\n",
            "Epoch: 575, Loss: 1.3002386735686173\n",
            "Epoch: 576, Loss: 1.3465593850359003\n",
            "Epoch: 577, Loss: 1.3231353328583089\n",
            "Epoch: 578, Loss: 1.3234039883241586\n",
            "Epoch: 579, Loss: 1.3080187055236059\n",
            "Epoch: 580, Loss: 1.3029690160818979\n",
            "Epoch: 581, Loss: 1.3233903485832486\n",
            "Epoch: 582, Loss: 1.2997078405204394\n",
            "Epoch: 583, Loss: 1.3384592879748514\n",
            "Epoch: 584, Loss: 1.3031781396121844\n",
            "Epoch: 585, Loss: 1.3449900065753477\n",
            "Epoch: 586, Loss: 1.3238863226369764\n",
            "Epoch: 587, Loss: 1.3223244560525773\n",
            "Epoch: 588, Loss: 1.2946473571425634\n",
            "Epoch: 589, Loss: 1.3382037556763235\n",
            "Epoch: 590, Loss: 1.286896933055093\n",
            "Epoch: 591, Loss: 1.3214635950453737\n",
            "Epoch: 592, Loss: 1.329154187905873\n",
            "Epoch: 593, Loss: 1.323223315232189\n",
            "Epoch: 594, Loss: 1.2971223449030667\n",
            "Epoch: 595, Loss: 1.2953989311312952\n",
            "Epoch: 596, Loss: 1.3103107543701822\n",
            "Epoch: 597, Loss: 1.3065988992122892\n",
            "Epoch: 598, Loss: 1.3197358153390546\n",
            "Epoch: 599, Loss: 1.3035740023809121\n",
            "Epoch: 600, Loss: 1.2987130635173607\n",
            "Epoch: 601, Loss: 1.3081783563532727\n",
            "Epoch: 602, Loss: 1.2902918242393655\n",
            "Epoch: 603, Loss: 1.3494784950364567\n",
            "Epoch: 604, Loss: 1.3343149888600017\n",
            "Epoch: 605, Loss: 1.3198232278756217\n",
            "Epoch: 606, Loss: 1.3445963496012046\n",
            "Epoch: 607, Loss: 1.331135612007574\n",
            "Epoch: 608, Loss: 1.296337350040463\n",
            "Epoch: 609, Loss: 1.3296896346071934\n",
            "Epoch: 610, Loss: 1.3116704132540007\n",
            "Epoch: 611, Loss: 1.310450680712436\n",
            "Epoch: 612, Loss: 1.3189978616457458\n",
            "Epoch: 613, Loss: 1.299083210052328\n",
            "Epoch: 614, Loss: 1.3480331162188914\n",
            "Epoch: 615, Loss: 1.330953356222058\n",
            "Epoch: 616, Loss: 1.330750696202542\n",
            "Epoch: 617, Loss: 1.324038918136705\n",
            "Epoch: 618, Loss: 1.3403702458591324\n",
            "Epoch: 619, Loss: 1.338903821106498\n",
            "Epoch: 620, Loss: 1.3098163875282234\n",
            "Epoch: 621, Loss: 1.3100907565854119\n",
            "Epoch: 622, Loss: 1.3320651401019266\n",
            "Epoch: 623, Loss: 1.3097181387826906\n",
            "Epoch: 624, Loss: 1.3222657585820408\n",
            "Epoch: 625, Loss: 1.3034287141569962\n",
            "Epoch: 626, Loss: 1.3133337108801442\n",
            "Epoch: 627, Loss: 1.3238637777085\n",
            "Epoch: 628, Loss: 1.3028960684512523\n",
            "Epoch: 629, Loss: 1.3240648254435112\n",
            "Epoch: 630, Loss: 1.3230937643254057\n",
            "Epoch: 631, Loss: 1.3155618914475677\n",
            "Epoch: 632, Loss: 1.3039965984669137\n",
            "Epoch: 633, Loss: 1.3271145871345034\n",
            "Epoch: 634, Loss: 1.326304149120412\n",
            "Epoch: 635, Loss: 1.3063515441637512\n",
            "Epoch: 636, Loss: 1.2954250126020281\n",
            "Epoch: 637, Loss: 1.3422994672829378\n",
            "Epoch: 638, Loss: 1.306310328185981\n",
            "Epoch: 639, Loss: 1.3233929517421317\n",
            "Epoch: 640, Loss: 1.309117245335951\n",
            "Epoch: 641, Loss: 1.3066810005945517\n",
            "Epoch: 642, Loss: 1.3236363153931097\n",
            "Epoch: 643, Loss: 1.2887872778777534\n",
            "Epoch: 644, Loss: 1.3171446086667107\n",
            "Epoch: 645, Loss: 1.3294287953816406\n",
            "Epoch: 646, Loss: 1.3038352186798203\n",
            "Epoch: 647, Loss: 1.306602117863107\n",
            "Epoch: 648, Loss: 1.2956205285187308\n",
            "Epoch: 649, Loss: 1.3073503548371876\n",
            "Epoch: 650, Loss: 1.3117980813303738\n",
            "Epoch: 651, Loss: 1.325399507022073\n",
            "Epoch: 652, Loss: 1.3080951491146222\n",
            "Epoch: 653, Loss: 1.3301996787389119\n",
            "Epoch: 654, Loss: 1.3035654336848157\n",
            "Epoch: 655, Loss: 1.3358060349809362\n",
            "Epoch: 656, Loss: 1.3165830027127097\n",
            "Epoch: 657, Loss: 1.3176211414607704\n",
            "Epoch: 658, Loss: 1.3103037844312952\n",
            "Epoch: 659, Loss: 1.2955344230570691\n",
            "Epoch: 660, Loss: 1.3182128955286445\n",
            "Epoch: 661, Loss: 1.2911037325013615\n",
            "Epoch: 662, Loss: 1.3201828831476523\n",
            "Epoch: 663, Loss: 1.3181510774801808\n",
            "Epoch: 664, Loss: 1.3309807413858725\n",
            "Epoch: 665, Loss: 1.282282514775053\n",
            "Epoch: 666, Loss: 1.2868077568974055\n",
            "Epoch: 667, Loss: 1.3296433678755524\n",
            "Epoch: 668, Loss: 1.289482945246054\n",
            "Epoch: 669, Loss: 1.318251314738118\n",
            "Epoch: 670, Loss: 1.2993800580924284\n",
            "Epoch: 671, Loss: 1.317463236497649\n",
            "Epoch: 672, Loss: 1.2838148123829076\n",
            "Epoch: 673, Loss: 1.3233326419870903\n",
            "Epoch: 674, Loss: 1.3326156435283363\n",
            "Epoch: 675, Loss: 1.3320119786769786\n",
            "Epoch: 676, Loss: 1.289230541980013\n",
            "Epoch: 677, Loss: 1.3024832035632843\n",
            "Epoch: 678, Loss: 1.296086477895155\n",
            "Epoch: 679, Loss: 1.351544091042052\n",
            "Epoch: 680, Loss: 1.331046054549251\n",
            "Epoch: 681, Loss: 1.3126784072700122\n",
            "Epoch: 682, Loss: 1.3334670498016032\n",
            "Epoch: 683, Loss: 1.3349878238448014\n",
            "Epoch: 684, Loss: 1.3038933818221938\n",
            "Epoch: 685, Loss: 1.3035519613441846\n",
            "Epoch: 686, Loss: 1.3126121708687315\n",
            "Epoch: 687, Loss: 1.2896170320240319\n",
            "Epoch: 688, Loss: 1.3293164283671277\n",
            "Epoch: 689, Loss: 1.3448301257816613\n",
            "Epoch: 690, Loss: 1.3110710264097714\n",
            "Epoch: 691, Loss: 1.2882622920029552\n",
            "Epoch: 692, Loss: 1.3039976874141828\n",
            "Epoch: 693, Loss: 1.2961705415806872\n",
            "Epoch: 694, Loss: 1.3044337693681107\n",
            "Epoch: 695, Loss: 1.2983306451892176\n",
            "Epoch: 696, Loss: 1.3045933263521667\n",
            "Epoch: 697, Loss: 1.2968812538376937\n",
            "Epoch: 698, Loss: 1.30260516819379\n",
            "Epoch: 699, Loss: 1.3230786805457257\n",
            "Epoch: 700, Loss: 1.2863266096047477\n",
            "Epoch: 701, Loss: 1.3099921113210367\n",
            "Epoch: 702, Loss: 1.3310795633505421\n",
            "Epoch: 703, Loss: 1.3367673386918737\n",
            "Epoch: 704, Loss: 1.3097284846272028\n",
            "Epoch: 705, Loss: 1.3097210226329505\n",
            "Epoch: 706, Loss: 1.2972325855958546\n",
            "Epoch: 707, Loss: 1.3069442180877036\n",
            "Epoch: 708, Loss: 1.307385635714159\n",
            "Epoch: 709, Loss: 1.2931913864528033\n",
            "Epoch: 710, Loss: 1.3150688308350582\n",
            "Epoch: 711, Loss: 1.3022978035270745\n",
            "Epoch: 712, Loss: 1.3031932698919417\n",
            "Epoch: 713, Loss: 1.3238009586401864\n",
            "Epoch: 714, Loss: 1.2902299740635756\n",
            "Epoch: 715, Loss: 1.2817507694799004\n",
            "Epoch: 716, Loss: 1.316743088952193\n",
            "Epoch: 717, Loss: 1.3116628058413242\n",
            "Epoch: 718, Loss: 1.3249094739873357\n",
            "Epoch: 719, Loss: 1.3185089978765934\n",
            "Epoch: 720, Loss: 1.3254066223793841\n",
            "Epoch: 721, Loss: 1.3136734345280532\n",
            "Epoch: 722, Loss: 1.3131856943698639\n",
            "Epoch: 723, Loss: 1.3171287707403196\n",
            "Epoch: 724, Loss: 1.3299518417804799\n",
            "Epoch: 725, Loss: 1.3145777401349223\n",
            "Epoch: 726, Loss: 1.3316094046788858\n",
            "Epoch: 727, Loss: 1.2815210497971121\n",
            "Epoch: 728, Loss: 1.308409166674242\n",
            "Epoch: 729, Loss: 1.3238812778012972\n",
            "Epoch: 730, Loss: 1.3205374589203096\n",
            "Epoch: 731, Loss: 1.3287502797782844\n",
            "Epoch: 732, Loss: 1.3237818530265322\n",
            "Epoch: 733, Loss: 1.3531197977404221\n",
            "Epoch: 734, Loss: 1.3321834396808705\n",
            "Epoch: 735, Loss: 1.3216468332507085\n",
            "Epoch: 736, Loss: 1.312810573172062\n",
            "Epoch: 737, Loss: 1.3298811346081132\n",
            "Epoch: 738, Loss: 1.288688231867256\n",
            "Epoch: 739, Loss: 1.307175875555539\n",
            "Epoch: 740, Loss: 1.3008195939638936\n",
            "Epoch: 741, Loss: 1.3214955727259319\n",
            "Epoch: 742, Loss: 1.3034341665024454\n",
            "Epoch: 743, Loss: 1.3111598956669475\n",
            "Epoch: 744, Loss: 1.315117357470465\n",
            "Epoch: 745, Loss: 1.3368208738083536\n",
            "Epoch: 746, Loss: 1.3135079830250842\n",
            "Epoch: 747, Loss: 1.3057852560746754\n",
            "Epoch: 748, Loss: 1.3074353163969432\n",
            "Epoch: 749, Loss: 1.3156905478619514\n",
            "Epoch: 750, Loss: 1.3020844738534156\n",
            "Epoch: 751, Loss: 1.3286007718837007\n",
            "Epoch: 752, Loss: 1.2994249915400296\n",
            "Epoch: 753, Loss: 1.2944956950262083\n",
            "Epoch: 754, Loss: 1.297569527693674\n",
            "Epoch: 755, Loss: 1.315433232496816\n",
            "Epoch: 756, Loss: 1.3118510026458308\n",
            "Epoch: 757, Loss: 1.290453368044914\n",
            "Epoch: 758, Loss: 1.3107990483020213\n",
            "Epoch: 759, Loss: 1.317665457725525\n",
            "Epoch: 760, Loss: 1.2872333780248113\n",
            "Epoch: 761, Loss: 1.2834035995158743\n",
            "Epoch: 762, Loss: 1.2998284845487444\n",
            "Epoch: 763, Loss: 1.2918356733119234\n",
            "Epoch: 764, Loss: 1.2975248411192115\n",
            "Epoch: 765, Loss: 1.290116308428717\n",
            "Epoch: 766, Loss: 1.2987631085916613\n",
            "Epoch: 767, Loss: 1.2772387824159988\n",
            "Epoch: 768, Loss: 1.3230835571356698\n",
            "Epoch: 769, Loss: 1.2952501790743347\n",
            "Epoch: 770, Loss: 1.2818226340814685\n",
            "Epoch: 771, Loss: 1.3077114076479106\n",
            "Epoch: 772, Loss: 1.2958825666008267\n",
            "Epoch: 773, Loss: 1.2947621396247377\n",
            "Epoch: 774, Loss: 1.2908658939050444\n",
            "Epoch: 775, Loss: 1.2899800395289212\n",
            "Epoch: 776, Loss: 1.3151404680089747\n",
            "Epoch: 777, Loss: 1.2790559986804393\n",
            "Epoch: 778, Loss: 1.2836582390129143\n",
            "Epoch: 779, Loss: 1.289201132794644\n",
            "Epoch: 780, Loss: 1.306981697995612\n",
            "Epoch: 781, Loss: 1.3176578900492784\n",
            "Epoch: 782, Loss: 1.2817173494514844\n",
            "Epoch: 783, Loss: 1.283817855178887\n",
            "Epoch: 784, Loss: 1.2816186204869695\n",
            "Epoch: 785, Loss: 1.3027678406830374\n",
            "Epoch: 786, Loss: 1.274526501378269\n",
            "Epoch: 787, Loss: 1.2864914845067559\n",
            "Epoch: 788, Loss: 1.3026015006058604\n",
            "Epoch: 789, Loss: 1.3059480646823314\n",
            "Epoch: 790, Loss: 1.2816440534929856\n",
            "Epoch: 791, Loss: 1.2923583189646404\n",
            "Epoch: 792, Loss: 1.2825431527820885\n",
            "Epoch: 793, Loss: 1.3106018693734567\n",
            "Epoch: 794, Loss: 1.2934532495255167\n",
            "Epoch: 795, Loss: 1.3096688968915466\n",
            "Epoch: 796, Loss: 1.292531261207364\n",
            "Epoch: 797, Loss: 1.3097171800356384\n",
            "Epoch: 798, Loss: 1.3150921874012507\n",
            "Epoch: 799, Loss: 1.310011975308682\n",
            "Epoch: 800, Loss: 1.28944867215258\n",
            "Epoch: 801, Loss: 1.324845533844427\n",
            "Epoch: 802, Loss: 1.311397669163156\n",
            "Epoch: 803, Loss: 1.3004042104626379\n",
            "Epoch: 804, Loss: 1.2995771110480558\n",
            "Epoch: 805, Loss: 1.2826704759124323\n",
            "Epoch: 806, Loss: 1.2956360367172999\n",
            "Epoch: 807, Loss: 1.284658411715893\n",
            "Epoch: 808, Loss: 1.307820664229968\n",
            "Epoch: 809, Loss: 1.2885711150811918\n",
            "Epoch: 810, Loss: 1.3225487343808437\n",
            "Epoch: 811, Loss: 1.2885844284761037\n",
            "Epoch: 812, Loss: 1.2996906050553558\n",
            "Epoch: 813, Loss: 1.3054459382456245\n",
            "Epoch: 814, Loss: 1.2824118729178786\n",
            "Epoch: 815, Loss: 1.2772870993783287\n",
            "Epoch: 816, Loss: 1.2825090470888936\n",
            "Epoch: 817, Loss: 1.296016141877952\n",
            "Epoch: 818, Loss: 1.295725293193303\n",
            "Epoch: 819, Loss: 1.288667048122866\n",
            "Epoch: 820, Loss: 1.2974829344039267\n",
            "Epoch: 821, Loss: 1.3030235725091703\n",
            "Epoch: 822, Loss: 1.2884987736424656\n",
            "Epoch: 823, Loss: 1.3018210179416845\n",
            "Epoch: 824, Loss: 1.3050416877083744\n",
            "Epoch: 825, Loss: 1.2948696410402338\n",
            "Epoch: 826, Loss: 1.2845604428162811\n",
            "Epoch: 827, Loss: 1.283664141140931\n",
            "Epoch: 828, Loss: 1.3164313270690593\n",
            "Epoch: 829, Loss: 1.2802612654706265\n",
            "Epoch: 830, Loss: 1.2789862426460212\n",
            "Epoch: 831, Loss: 1.2910267063911924\n",
            "Epoch: 832, Loss: 1.3026927236124133\n",
            "Epoch: 833, Loss: 1.282792032187712\n",
            "Epoch: 834, Loss: 1.2942231039628915\n",
            "Epoch: 835, Loss: 1.3080963259893106\n",
            "Epoch: 836, Loss: 1.2816843377782943\n",
            "Epoch: 837, Loss: 1.2742944507734149\n",
            "Epoch: 838, Loss: 1.2796546449052526\n",
            "Epoch: 839, Loss: 1.281664993746061\n",
            "Epoch: 840, Loss: 1.2865828901317948\n",
            "Epoch: 841, Loss: 1.2897798448589677\n",
            "Epoch: 842, Loss: 1.2903526184406686\n",
            "Epoch: 843, Loss: 1.2893220972507557\n",
            "Epoch: 844, Loss: 1.3053879146034835\n",
            "Epoch: 845, Loss: 1.2892133834514212\n",
            "Epoch: 846, Loss: 1.295126622450267\n",
            "Epoch: 847, Loss: 1.2888722707193794\n",
            "Epoch: 848, Loss: 1.2960491112783445\n",
            "Epoch: 849, Loss: 1.2846433786635703\n",
            "Epoch: 850, Loss: 1.282805396309981\n",
            "Epoch: 851, Loss: 1.2882350201302386\n",
            "Epoch: 852, Loss: 1.2885124370561423\n",
            "Epoch: 853, Loss: 1.2887155164218118\n",
            "Epoch: 854, Loss: 1.298380987864014\n",
            "Epoch: 855, Loss: 1.304066427210544\n",
            "Epoch: 856, Loss: 1.2813372611999512\n",
            "Epoch: 857, Loss: 1.2831712546923482\n",
            "Epoch: 858, Loss: 1.2985719983459365\n",
            "Epoch: 859, Loss: 1.275948481356844\n",
            "Epoch: 860, Loss: 1.3051964619480971\n",
            "Epoch: 861, Loss: 1.3083893086047882\n",
            "Epoch: 862, Loss: 1.2979093527962975\n",
            "Epoch: 863, Loss: 1.2891870246711352\n",
            "Epoch: 864, Loss: 1.2770227650378612\n",
            "Epoch: 865, Loss: 1.2925701614812757\n",
            "Epoch: 866, Loss: 1.2962976482743067\n",
            "Epoch: 867, Loss: 1.2990061687239518\n",
            "Epoch: 868, Loss: 1.2939003908887823\n",
            "Epoch: 869, Loss: 1.275530474405762\n",
            "Epoch: 870, Loss: 1.281993841448574\n",
            "Epoch: 871, Loss: 1.287442498173274\n",
            "Epoch: 872, Loss: 1.2918326787069334\n",
            "Epoch: 873, Loss: 1.2912310311134825\n",
            "Epoch: 874, Loss: 1.2813326475468088\n",
            "Epoch: 875, Loss: 1.311611055482364\n",
            "Epoch: 876, Loss: 1.290174698153286\n",
            "Epoch: 877, Loss: 1.2750836872885414\n",
            "Epoch: 878, Loss: 1.2800722671738753\n",
            "Epoch: 879, Loss: 1.2993838026168498\n",
            "Epoch: 880, Loss: 1.2863026071102062\n",
            "Epoch: 881, Loss: 1.2987090915652877\n",
            "Epoch: 882, Loss: 1.2811925622588354\n",
            "Epoch: 883, Loss: 1.2914979855219524\n",
            "Epoch: 884, Loss: 1.2787807461217786\n",
            "Epoch: 885, Loss: 1.2841439889677873\n",
            "Epoch: 886, Loss: 1.2767853415604178\n",
            "Epoch: 887, Loss: 1.2945749954128942\n",
            "Epoch: 888, Loss: 1.3099549839682612\n",
            "Epoch: 889, Loss: 1.2916012275303508\n",
            "Epoch: 890, Loss: 1.288808432031185\n",
            "Epoch: 891, Loss: 1.3027443133347423\n",
            "Epoch: 892, Loss: 1.290384882730795\n",
            "Epoch: 893, Loss: 1.295054575230213\n",
            "Epoch: 894, Loss: 1.2842521016479385\n",
            "Epoch: 895, Loss: 1.2909054105163467\n",
            "Epoch: 896, Loss: 1.3015235924551674\n",
            "Epoch: 897, Loss: 1.2916865475634312\n",
            "Epoch: 898, Loss: 1.301083778658657\n",
            "Epoch: 899, Loss: 1.2873194437500433\n",
            "Epoch: 900, Loss: 1.2765481767924964\n",
            "Epoch: 901, Loss: 1.2859935270133593\n",
            "Epoch: 902, Loss: 1.280609517232746\n",
            "Epoch: 903, Loss: 1.3021702081599134\n",
            "Epoch: 904, Loss: 1.2970273596175173\n",
            "Epoch: 905, Loss: 1.306054483914206\n",
            "Epoch: 906, Loss: 1.300948198805464\n",
            "Epoch: 907, Loss: 1.2827068990003978\n",
            "Epoch: 908, Loss: 1.2928994166935588\n",
            "Epoch: 909, Loss: 1.2998156826546852\n",
            "Epoch: 910, Loss: 1.2888409220580512\n",
            "Epoch: 911, Loss: 1.3041168087763144\n",
            "Epoch: 912, Loss: 1.2883218044930316\n",
            "Epoch: 913, Loss: 1.296496848688058\n",
            "Epoch: 914, Loss: 1.3047097253461255\n",
            "Epoch: 915, Loss: 1.2815245846484569\n",
            "Epoch: 916, Loss: 1.2956720218590811\n",
            "Epoch: 917, Loss: 1.2833406629291833\n",
            "Epoch: 918, Loss: 1.2793167525149407\n",
            "Epoch: 919, Loss: 1.305032454483898\n",
            "Epoch: 920, Loss: 1.301597054968489\n",
            "Epoch: 921, Loss: 1.2891612399554422\n",
            "Epoch: 922, Loss: 1.2884110981690968\n",
            "Epoch: 923, Loss: 1.3191318579599367\n",
            "Epoch: 924, Loss: 1.2789397273503296\n",
            "Epoch: 925, Loss: 1.295482372561245\n",
            "Epoch: 926, Loss: 1.3094947625559272\n",
            "Epoch: 927, Loss: 1.288537213988338\n",
            "Epoch: 928, Loss: 1.2976162070078208\n",
            "Epoch: 929, Loss: 1.311781421620795\n",
            "Epoch: 930, Loss: 1.2888448229918243\n",
            "Epoch: 931, Loss: 1.2848281209350478\n",
            "Epoch: 932, Loss: 1.2947237153425284\n",
            "Epoch: 933, Loss: 1.2954076638458467\n",
            "Epoch: 934, Loss: 1.2844322590117758\n",
            "Epoch: 935, Loss: 1.2969133651002924\n",
            "Epoch: 936, Loss: 1.294101410723747\n",
            "Epoch: 937, Loss: 1.309439036017614\n",
            "Epoch: 938, Loss: 1.2811695540204961\n",
            "Epoch: 939, Loss: 1.3035225961225252\n",
            "Epoch: 940, Loss: 1.3001602431561083\n",
            "Epoch: 941, Loss: 1.2817795158278011\n",
            "Epoch: 942, Loss: 1.2951091316574854\n",
            "Epoch: 943, Loss: 1.2884939097343606\n",
            "Epoch: 944, Loss: 1.3142584892029459\n",
            "Epoch: 945, Loss: 1.2743566940862237\n",
            "Epoch: 946, Loss: 1.3058611873193835\n",
            "Epoch: 947, Loss: 1.3046937800468281\n",
            "Epoch: 948, Loss: 1.2851129863279085\n",
            "Epoch: 949, Loss: 1.3024063262533634\n",
            "Epoch: 950, Loss: 1.2888280702820907\n",
            "Epoch: 951, Loss: 1.2762496403768553\n",
            "Epoch: 952, Loss: 1.2815268496249583\n",
            "Epoch: 953, Loss: 1.2900411347125438\n",
            "Epoch: 954, Loss: 1.2953200779908092\n",
            "Epoch: 955, Loss: 1.2871141146260796\n",
            "Epoch: 956, Loss: 1.2889417485987886\n",
            "Epoch: 957, Loss: 1.3066403358540637\n",
            "Epoch: 958, Loss: 1.2900641911418724\n",
            "Epoch: 959, Loss: 1.2876194690136198\n",
            "Epoch: 960, Loss: 1.2966340526621392\n",
            "Epoch: 961, Loss: 1.2900193287125716\n",
            "Epoch: 962, Loss: 1.2770154188710747\n",
            "Epoch: 963, Loss: 1.3065197619986026\n",
            "Epoch: 964, Loss: 1.2822894948594112\n",
            "Epoch: 965, Loss: 1.2816405440053196\n",
            "Epoch: 966, Loss: 1.2941527899275433\n",
            "Epoch: 967, Loss: 1.2811627404909607\n",
            "Epoch: 968, Loss: 1.297546736737515\n",
            "Epoch: 969, Loss: 1.2884307719291523\n",
            "Epoch: 970, Loss: 1.2839983549523861\n",
            "Epoch: 971, Loss: 1.28389281161288\n",
            "Epoch: 972, Loss: 1.281462793654584\n",
            "Epoch: 973, Loss: 1.2887660070514002\n",
            "Epoch: 974, Loss: 1.2897803107051984\n",
            "Epoch: 975, Loss: 1.2971275047207556\n",
            "Epoch: 976, Loss: 1.3028853455333844\n",
            "Epoch: 977, Loss: 1.3019610398204613\n",
            "Epoch: 978, Loss: 1.297701839014148\n",
            "Epoch: 979, Loss: 1.2812089869316587\n",
            "Epoch: 980, Loss: 1.2911428221574066\n",
            "Epoch: 981, Loss: 1.2969534329488768\n",
            "Epoch: 982, Loss: 1.2957464989195477\n",
            "Epoch: 983, Loss: 1.2885884080372803\n",
            "Epoch: 984, Loss: 1.303791785916538\n",
            "Epoch: 985, Loss: 1.2979498518274186\n",
            "Epoch: 986, Loss: 1.28842575076624\n",
            "Epoch: 987, Loss: 1.3025446098746982\n",
            "Epoch: 988, Loss: 1.2821260868234836\n",
            "Epoch: 989, Loss: 1.3110388585016237\n",
            "Epoch: 990, Loss: 1.2961656920453335\n",
            "Epoch: 991, Loss: 1.2886872367655977\n",
            "Epoch: 992, Loss: 1.2888556845644688\n",
            "Epoch: 993, Loss: 1.2957138321923871\n",
            "Epoch: 994, Loss: 1.3024235845457577\n",
            "Epoch: 995, Loss: 1.285654181284262\n",
            "Epoch: 996, Loss: 1.3021892706553142\n",
            "Epoch: 997, Loss: 1.2990182866441442\n",
            "Epoch: 998, Loss: 1.2836909885947585\n",
            "Epoch: 999, Loss: 1.2812553466634546\n",
            "Epoch: 1000, Loss: 1.299799236845463\n",
            "Epoch: 1001, Loss: 1.2853974974747244\n",
            "Epoch: 1002, Loss: 1.2839467068935961\n",
            "Epoch: 1003, Loss: 1.2896799948198576\n",
            "Epoch: 1004, Loss: 1.3024368911770219\n",
            "Epoch: 1005, Loss: 1.2982288573650602\n",
            "Epoch: 1006, Loss: 1.285889613712933\n",
            "Epoch: 1007, Loss: 1.3028463395774788\n",
            "Epoch: 1008, Loss: 1.2961234209385324\n",
            "Epoch: 1009, Loss: 1.2816773644575836\n",
            "Epoch: 1010, Loss: 1.2945725283724197\n",
            "Epoch: 1011, Loss: 1.303926649668538\n",
            "Epoch: 1012, Loss: 1.2909640733231889\n",
            "Epoch: 1013, Loss: 1.2996355591090858\n",
            "Epoch: 1014, Loss: 1.3036073759092506\n",
            "Epoch: 1015, Loss: 1.2811931743689462\n",
            "Epoch: 1016, Loss: 1.2860704744961244\n",
            "Epoch: 1017, Loss: 1.2909495965808842\n",
            "Epoch: 1018, Loss: 1.283817949869954\n",
            "Epoch: 1019, Loss: 1.292701576618438\n",
            "Epoch: 1020, Loss: 1.2747230614330751\n",
            "Epoch: 1021, Loss: 1.2863157987594604\n",
            "Epoch: 1022, Loss: 1.2798626887882854\n",
            "Epoch: 1023, Loss: 1.282697559248471\n",
            "Epoch: 1024, Loss: 1.2830482915783605\n",
            "Epoch: 1025, Loss: 1.2860629795290899\n",
            "Epoch: 1026, Loss: 1.29343207761751\n",
            "Epoch: 1027, Loss: 1.2757295234828976\n",
            "Epoch: 1028, Loss: 1.274149567522901\n",
            "Epoch: 1029, Loss: 1.2742240564197513\n",
            "Epoch: 1030, Loss: 1.2880013775318226\n",
            "Epoch: 1031, Loss: 1.2849619016579703\n",
            "Epoch: 1032, Loss: 1.295458840140214\n",
            "Epoch: 1033, Loss: 1.3124660693161876\n",
            "Epoch: 1034, Loss: 1.2883841703969536\n",
            "Epoch: 1035, Loss: 1.2808533906936646\n",
            "Epoch: 1036, Loss: 1.2811483127851013\n",
            "Epoch: 1037, Loss: 1.313789832676556\n",
            "Epoch: 1038, Loss: 1.2740971619355763\n",
            "Epoch: 1039, Loss: 1.293108307723458\n",
            "Epoch: 1040, Loss: 1.291307253195039\n",
            "Epoch: 1041, Loss: 1.2745589660414567\n",
            "Epoch: 1042, Loss: 1.2963586174849921\n",
            "Epoch: 1043, Loss: 1.3025632225875312\n",
            "Epoch: 1044, Loss: 1.295442185503371\n",
            "Epoch: 1045, Loss: 1.2745541021333517\n",
            "Epoch: 1046, Loss: 1.2964932715639155\n",
            "Epoch: 1047, Loss: 1.2940900883776076\n",
            "Epoch: 1048, Loss: 1.291187009912856\n",
            "Epoch: 1049, Loss: 1.2817550711597956\n",
            "Epoch: 1050, Loss: 1.336961841752343\n",
            "Epoch: 1051, Loss: 1.28168028043517\n",
            "Epoch: 1052, Loss: 1.3088353153661634\n",
            "Epoch: 1053, Loss: 1.281313288296368\n",
            "Epoch: 1054, Loss: 1.2913651398733152\n",
            "Epoch: 1055, Loss: 1.2813496420569452\n",
            "Epoch: 1056, Loss: 1.2747481748567404\n",
            "Epoch: 1057, Loss: 1.2956078483703288\n",
            "Epoch: 1058, Loss: 1.2948979029418728\n",
            "Epoch: 1059, Loss: 1.2867048302440778\n",
            "Epoch: 1060, Loss: 1.2814508558165096\n",
            "Epoch: 1061, Loss: 1.288747822984736\n",
            "Epoch: 1062, Loss: 1.2816407849602665\n",
            "Epoch: 1063, Loss: 1.2951362936209279\n",
            "Epoch: 1064, Loss: 1.3048197047930237\n",
            "Epoch: 1065, Loss: 1.2916454550222303\n",
            "Epoch: 1066, Loss: 1.2882553753277934\n",
            "Epoch: 1067, Loss: 1.2812992038456261\n",
            "Epoch: 1068, Loss: 1.2876226682189509\n",
            "Epoch: 1069, Loss: 1.3049359262412321\n",
            "Epoch: 1070, Loss: 1.281656211149608\n",
            "Epoch: 1071, Loss: 1.274101937916262\n",
            "Epoch: 1072, Loss: 1.2814210746305208\n",
            "Epoch: 1073, Loss: 1.285266842402465\n",
            "Epoch: 1074, Loss: 1.2916718865117283\n",
            "Epoch: 1075, Loss: 1.3015956067024392\n",
            "Epoch: 1076, Loss: 1.2878348556816155\n",
            "Epoch: 1077, Loss: 1.3026071228879563\n",
            "Epoch: 1078, Loss: 1.2899166709142373\n",
            "Epoch: 1079, Loss: 1.2882444545732321\n",
            "Epoch: 1080, Loss: 1.2911081981997117\n",
            "Epoch: 1081, Loss: 1.2878739681649716\n",
            "Epoch: 1082, Loss: 1.281109683902551\n",
            "Epoch: 1083, Loss: 1.285235196986097\n",
            "Epoch: 1084, Loss: 1.2741146256737674\n",
            "Epoch: 1085, Loss: 1.3060850006468752\n",
            "Epoch: 1086, Loss: 1.2972622703998646\n",
            "Epoch: 1087, Loss: 1.3098533728443984\n",
            "Epoch: 1088, Loss: 1.2953989311312952\n",
            "Epoch: 1089, Loss: 1.2885075486298148\n",
            "Epoch: 1090, Loss: 1.302532601018324\n",
            "Epoch: 1091, Loss: 1.2918396875367941\n",
            "Epoch: 1092, Loss: 1.2909201282135983\n",
            "Epoch: 1093, Loss: 1.2997784276380606\n",
            "Epoch: 1094, Loss: 1.281229589847808\n",
            "Epoch: 1095, Loss: 1.2977038790993656\n",
            "Epoch: 1096, Loss: 1.2802579774924203\n",
            "Epoch: 1097, Loss: 1.2752795557603769\n",
            "Epoch: 1098, Loss: 1.2826183476346604\n",
            "Epoch: 1099, Loss: 1.2821546801438568\n",
            "Epoch: 1100, Loss: 1.2813640765264525\n",
            "Epoch: 1101, Loss: 1.2879078066940848\n",
            "Epoch: 1102, Loss: 1.2885685034677492\n",
            "Epoch: 1103, Loss: 1.291197989849334\n",
            "Epoch: 1104, Loss: 1.2799063853338255\n",
            "Epoch: 1105, Loss: 1.3084579782283052\n",
            "Epoch: 1106, Loss: 1.2864046680166366\n",
            "Epoch: 1107, Loss: 1.2881937956979088\n",
            "Epoch: 1108, Loss: 1.2954956555197426\n",
            "Epoch: 1109, Loss: 1.2801805912180149\n",
            "Epoch: 1110, Loss: 1.2891406412665725\n",
            "Epoch: 1111, Loss: 1.3037484089533489\n",
            "Epoch: 1112, Loss: 1.2917140460183434\n",
            "Epoch: 1113, Loss: 1.288999575249692\n",
            "Epoch: 1114, Loss: 1.2882257742239227\n",
            "Epoch: 1115, Loss: 1.3024571313925668\n",
            "Epoch: 1116, Loss: 1.2752752743714244\n",
            "Epoch: 1117, Loss: 1.281468058308811\n",
            "Epoch: 1118, Loss: 1.3031795456054363\n",
            "Epoch: 1119, Loss: 1.2890745401382446\n",
            "Epoch: 1120, Loss: 1.2934709381549916\n",
            "Epoch: 1121, Loss: 1.281163530992278\n",
            "Epoch: 1122, Loss: 1.2928467853694943\n",
            "Epoch: 1123, Loss: 1.281219462130932\n",
            "Epoch: 1124, Loss: 1.2802011527068227\n",
            "Epoch: 1125, Loss: 1.2961666144377797\n",
            "Epoch: 1126, Loss: 1.2745938410995699\n",
            "Epoch: 1127, Loss: 1.2918410901482222\n",
            "Epoch: 1128, Loss: 1.2814100025393438\n",
            "Epoch: 1129, Loss: 1.2962298731431894\n",
            "Epoch: 1130, Loss: 1.2812638299684997\n",
            "Epoch: 1131, Loss: 1.2880322459741687\n",
            "Epoch: 1132, Loss: 1.2957774333074583\n",
            "Epoch: 1133, Loss: 1.2740658242651757\n",
            "Epoch: 1134, Loss: 1.2758807028439028\n",
            "Epoch: 1135, Loss: 1.2834381812007714\n",
            "Epoch: 1136, Loss: 1.2843869662453942\n",
            "Epoch: 1137, Loss: 1.2772478228765176\n",
            "Epoch: 1138, Loss: 1.2816926596012521\n",
            "Epoch: 1139, Loss: 1.3025714319648471\n",
            "Epoch: 1140, Loss: 1.2982650504890063\n",
            "Epoch: 1141, Loss: 1.2840122525573623\n",
            "Epoch: 1142, Loss: 1.2812304851856637\n",
            "Epoch: 1143, Loss: 1.2956322059563712\n",
            "Epoch: 1144, Loss: 1.288347082780608\n",
            "Epoch: 1145, Loss: 1.2953242900523734\n",
            "Epoch: 1146, Loss: 1.2977014222043626\n",
            "Epoch: 1147, Loss: 1.2883968471635319\n",
            "Epoch: 1148, Loss: 1.275828552584276\n",
            "Epoch: 1149, Loss: 1.2883289232321664\n",
            "Epoch: 1150, Loss: 1.2953372661103593\n",
            "Epoch: 1151, Loss: 1.2811118051515402\n",
            "Epoch: 1152, Loss: 1.3031249054780243\n",
            "Epoch: 1153, Loss: 1.2954077602278256\n",
            "Epoch: 1154, Loss: 1.2884337090431375\n",
            "Epoch: 1155, Loss: 1.2886835235230465\n",
            "Epoch: 1156, Loss: 1.2876358319681587\n",
            "Epoch: 1157, Loss: 1.286226619219949\n",
            "Epoch: 1158, Loss: 1.2741265051753807\n",
            "Epoch: 1159, Loss: 1.2954433471598523\n",
            "Epoch: 1160, Loss: 1.2811847155821239\n",
            "Epoch: 1161, Loss: 1.3031025769862723\n",
            "Epoch: 1162, Loss: 1.2857899581286925\n",
            "Epoch: 1163, Loss: 1.2882223467454843\n",
            "Epoch: 1164, Loss: 1.281617599176177\n",
            "Epoch: 1165, Loss: 1.3108254840187992\n",
            "Epoch: 1166, Loss: 1.2882804963605623\n",
            "Epoch: 1167, Loss: 1.324267844781808\n",
            "Epoch: 1168, Loss: 1.3034086700872327\n",
            "Epoch: 1169, Loss: 1.2882552392093847\n",
            "Epoch: 1170, Loss: 1.2844307921456952\n",
            "Epoch: 1171, Loss: 1.2812221853445607\n",
            "Epoch: 1172, Loss: 1.284131998711444\n",
            "Epoch: 1173, Loss: 1.2880281463582464\n",
            "Epoch: 1174, Loss: 1.298121634950029\n",
            "Epoch: 1175, Loss: 1.281863347012946\n",
            "Epoch: 1176, Loss: 1.2811047599670735\n",
            "Epoch: 1177, Loss: 1.2823770553507703\n",
            "Epoch: 1178, Loss: 1.2928896964864527\n",
            "Epoch: 1179, Loss: 1.2824139053939927\n",
            "Epoch: 1180, Loss: 1.2882237704933113\n",
            "Epoch: 1181, Loss: 1.2750706342940634\n",
            "Epoch: 1182, Loss: 1.2812511523564656\n",
            "Epoch: 1183, Loss: 1.2906813148065661\n",
            "Epoch: 1184, Loss: 1.295928735259577\n",
            "Epoch: 1185, Loss: 1.3016260042258188\n",
            "Epoch: 1186, Loss: 1.2889053703199886\n",
            "Epoch: 1187, Loss: 1.2951186134460124\n",
            "Epoch: 1188, Loss: 1.2960024725460837\n",
            "Epoch: 1189, Loss: 1.2858431491445987\n",
            "Epoch: 1190, Loss: 1.2829724507974394\n",
            "Epoch: 1191, Loss: 1.2832719383510292\n",
            "Epoch: 1192, Loss: 1.282285046915636\n",
            "Epoch: 1193, Loss: 1.286367767246057\n",
            "Epoch: 1194, Loss: 1.2960890438539763\n",
            "Epoch: 1195, Loss: 1.2813782277682149\n",
            "Epoch: 1196, Loss: 1.2765682901896482\n",
            "Epoch: 1197, Loss: 1.2892754602094068\n",
            "Epoch: 1198, Loss: 1.293434646112699\n",
            "Epoch: 1199, Loss: 1.2921924743246525\n",
            "Epoch: 1200, Loss: 1.316629467281044\n",
            "Epoch: 1201, Loss: 1.281577837382648\n",
            "Epoch: 1202, Loss: 1.2887985486510798\n",
            "Epoch: 1203, Loss: 1.2893760508679328\n",
            "Epoch: 1204, Loss: 1.2814675375079432\n",
            "Epoch: 1205, Loss: 1.29536117475929\n",
            "Epoch: 1206, Loss: 1.2749307798155656\n",
            "Epoch: 1207, Loss: 1.2956709083935893\n",
            "Epoch: 1208, Loss: 1.295926216646289\n",
            "Epoch: 1209, Loss: 1.288213088157329\n",
            "Epoch: 1210, Loss: 1.2951436558513776\n",
            "Epoch: 1211, Loss: 1.2742240750197822\n",
            "Epoch: 1212, Loss: 1.2920475006103516\n",
            "Epoch: 1213, Loss: 1.2744483609571524\n",
            "Epoch: 1214, Loss: 1.3006817914069966\n",
            "Epoch: 1215, Loss: 1.2882170508093866\n",
            "Epoch: 1216, Loss: 1.2964748380877447\n",
            "Epoch: 1217, Loss: 1.3006855139495632\n",
            "Epoch: 1218, Loss: 1.295437198158697\n",
            "Epoch: 1219, Loss: 1.297166333130911\n",
            "Epoch: 1220, Loss: 1.2741446782511177\n",
            "Epoch: 1221, Loss: 1.2882698622155697\n",
            "Epoch: 1222, Loss: 1.2815402720836881\n",
            "Epoch: 1223, Loss: 1.2883497087668019\n",
            "Epoch: 1224, Loss: 1.2741476906106828\n",
            "Epoch: 1225, Loss: 1.302404487386663\n",
            "Epoch: 1226, Loss: 1.2813144879983671\n",
            "Epoch: 1227, Loss: 1.2798047547644757\n",
            "Epoch: 1228, Loss: 1.2955433054173247\n",
            "Epoch: 1229, Loss: 1.2953646605741893\n",
            "Epoch: 1230, Loss: 1.3031009308835293\n",
            "Epoch: 1231, Loss: 1.2784761883688311\n",
            "Epoch: 1232, Loss: 1.2880663119309337\n",
            "Epoch: 1233, Loss: 1.2884294394905684\n",
            "Epoch: 1234, Loss: 1.2855721991112892\n",
            "Epoch: 1235, Loss: 1.2740112771379186\n",
            "Epoch: 1236, Loss: 1.2811404889357005\n",
            "Epoch: 1237, Loss: 1.2811684422459162\n",
            "Epoch: 1238, Loss: 1.2882524162319535\n",
            "Epoch: 1239, Loss: 1.2823550887141668\n",
            "Epoch: 1240, Loss: 1.2811376456673262\n",
            "Epoch: 1241, Loss: 1.2821718403633604\n",
            "Epoch: 1242, Loss: 1.2882088752503091\n",
            "Epoch: 1243, Loss: 1.282761828273746\n",
            "Epoch: 1244, Loss: 1.3096805455836844\n",
            "Epoch: 1245, Loss: 1.2826274591134794\n",
            "Epoch: 1246, Loss: 1.2741100754298216\n",
            "Epoch: 1247, Loss: 1.2809348926476554\n",
            "Epoch: 1248, Loss: 1.2981522666647078\n",
            "Epoch: 1249, Loss: 1.2893690868472376\n",
            "Epoch: 1250, Loss: 1.2891020656477474\n",
            "Epoch: 1251, Loss: 1.290068065021055\n",
            "Epoch: 1252, Loss: 1.2931081842868886\n",
            "Epoch: 1253, Loss: 1.302592952200707\n",
            "Epoch: 1254, Loss: 1.2879385533907735\n",
            "Epoch: 1255, Loss: 1.2957066263712889\n",
            "Epoch: 1256, Loss: 1.2835767911681046\n",
            "Epoch: 1257, Loss: 1.2950462677800063\n",
            "Epoch: 1258, Loss: 1.2944139335172395\n",
            "Epoch: 1259, Loss: 1.274259772706539\n",
            "Epoch: 1260, Loss: 1.3094864415784253\n",
            "Epoch: 1261, Loss: 1.2740235362492554\n",
            "Epoch: 1262, Loss: 1.2887281458428566\n",
            "Epoch: 1263, Loss: 1.3090194201638512\n",
            "Epoch: 1264, Loss: 1.2954940516897973\n",
            "Epoch: 1265, Loss: 1.2891960904953328\n",
            "Epoch: 1266, Loss: 1.2806032160495189\n",
            "Epoch: 1267, Loss: 1.2929005326954186\n",
            "Epoch: 1268, Loss: 1.2882204199513645\n",
            "Epoch: 1269, Loss: 1.2959618644511446\n",
            "Epoch: 1270, Loss: 1.295507957749333\n",
            "Epoch: 1271, Loss: 1.2958531582609136\n",
            "Epoch: 1272, Loss: 1.2818289378010634\n",
            "Epoch: 1273, Loss: 1.297317940292629\n",
            "Epoch: 1274, Loss: 1.288166232988344\n",
            "Epoch: 1275, Loss: 1.2812053506255996\n",
            "Epoch: 1276, Loss: 1.2746657352920965\n",
            "Epoch: 1277, Loss: 1.2885944750292082\n",
            "Epoch: 1278, Loss: 1.2882678855395486\n",
            "Epoch: 1279, Loss: 1.2972014888804009\n",
            "Epoch: 1280, Loss: 1.285003290954211\n",
            "Epoch: 1281, Loss: 1.2812747194411906\n",
            "Epoch: 1282, Loss: 1.286749244581723\n",
            "Epoch: 1283, Loss: 1.2952368048065943\n",
            "Epoch: 1284, Loss: 1.2843860911984815\n",
            "Epoch: 1285, Loss: 1.3069963861019054\n",
            "Epoch: 1286, Loss: 1.288416345068749\n",
            "Epoch: 1287, Loss: 1.2812121531642076\n",
            "Epoch: 1288, Loss: 1.2921357467664893\n",
            "Epoch: 1289, Loss: 1.281127337022876\n",
            "Epoch: 1290, Loss: 1.2816787670690117\n",
            "Epoch: 1291, Loss: 1.2882750211878025\n",
            "Epoch: 1292, Loss: 1.2953914573006595\n",
            "Epoch: 1293, Loss: 1.2960506035081039\n",
            "Epoch: 1294, Loss: 1.276287724785771\n",
            "Epoch: 1295, Loss: 1.312901956815246\n",
            "Epoch: 1296, Loss: 1.2889026724700385\n",
            "Epoch: 1297, Loss: 1.2779655718634315\n",
            "Epoch: 1298, Loss: 1.2841038991373481\n",
            "Epoch: 1299, Loss: 1.2812680530209912\n",
            "Epoch: 1300, Loss: 1.3178628471726221\n",
            "Epoch: 1301, Loss: 1.2896680730454464\n",
            "Epoch: 1302, Loss: 1.2881990400611931\n",
            "Epoch: 1303, Loss: 1.295379360516866\n",
            "Epoch: 1304, Loss: 1.2748675101192284\n",
            "Epoch: 1305, Loss: 1.288726215666913\n",
            "Epoch: 1306, Loss: 1.2746743251245918\n",
            "Epoch: 1307, Loss: 1.2973850821772366\n",
            "Epoch: 1308, Loss: 1.2968456398510764\n",
            "Epoch: 1309, Loss: 1.2740388626747943\n",
            "Epoch: 1310, Loss: 1.274135393453828\n",
            "Epoch: 1311, Loss: 1.2892331578207354\n",
            "Epoch: 1312, Loss: 1.2878723322077\n",
            "Epoch: 1313, Loss: 1.2886045816096854\n",
            "Epoch: 1314, Loss: 1.2875625275551004\n",
            "Epoch: 1315, Loss: 1.302598237145877\n",
            "Epoch: 1316, Loss: 1.2850081540168599\n",
            "Epoch: 1317, Loss: 1.30136842000569\n",
            "Epoch: 1318, Loss: 1.2943510096123878\n",
            "Epoch: 1319, Loss: 1.2903934015449903\n",
            "Epoch: 1320, Loss: 1.2966683359010844\n",
            "Epoch: 1321, Loss: 1.2922102770906814\n",
            "Epoch: 1322, Loss: 1.2953129550243945\n",
            "Epoch: 1323, Loss: 1.2812927817621975\n",
            "Epoch: 1324, Loss: 1.2887303406465138\n",
            "Epoch: 1325, Loss: 1.303968055873898\n",
            "Epoch: 1326, Loss: 1.295817641501731\n",
            "Epoch: 1327, Loss: 1.2883184066055513\n",
            "Epoch: 1328, Loss: 1.2812223358357206\n",
            "Epoch: 1329, Loss: 1.2953000364574134\n",
            "Epoch: 1330, Loss: 1.2889600527201983\n",
            "Epoch: 1331, Loss: 1.288261723011098\n",
            "Epoch: 1332, Loss: 1.2794948588026331\n",
            "Epoch: 1333, Loss: 1.2875821294514\n",
            "Epoch: 1334, Loss: 1.2879355748494465\n",
            "Epoch: 1335, Loss: 1.2813445684757638\n",
            "Epoch: 1336, Loss: 1.2954552883797503\n",
            "Epoch: 1337, Loss: 1.274020571235224\n",
            "Epoch: 1338, Loss: 1.288399542477114\n",
            "Epoch: 1339, Loss: 1.2810964195440846\n",
            "Epoch: 1340, Loss: 1.2820481814391225\n",
            "Epoch: 1341, Loss: 1.2918263961237373\n",
            "Epoch: 1342, Loss: 1.2958036373693047\n",
            "Epoch: 1343, Loss: 1.3077616378770651\n",
            "Epoch: 1344, Loss: 1.2979351671029489\n",
            "Epoch: 1345, Loss: 1.2811060526692275\n",
            "Epoch: 1346, Loss: 1.2813540240551562\n",
            "Epoch: 1347, Loss: 1.2870879080278654\n",
            "Epoch: 1348, Loss: 1.3024795241389715\n",
            "Epoch: 1349, Loss: 1.3096784378619903\n",
            "Epoch: 1350, Loss: 1.3025088403241853\n",
            "Epoch: 1351, Loss: 1.2872854116115164\n",
            "Epoch: 1352, Loss: 1.3023255167277992\n",
            "Epoch: 1353, Loss: 1.274030787724975\n",
            "Epoch: 1354, Loss: 1.2884469615652205\n",
            "Epoch: 1355, Loss: 1.2753496542044565\n",
            "Epoch: 1356, Loss: 1.3026188409074824\n",
            "Epoch: 1357, Loss: 1.2811162336498287\n",
            "Epoch: 1358, Loss: 1.2827373311874715\n",
            "Epoch: 1359, Loss: 1.2882200673962316\n",
            "Epoch: 1360, Loss: 1.2921135146567162\n",
            "Epoch: 1361, Loss: 1.280285488629172\n",
            "Epoch: 1362, Loss: 1.2952730300578665\n",
            "Epoch: 1363, Loss: 1.3024013989360619\n",
            "Epoch: 1364, Loss: 1.2811171814059534\n",
            "Epoch: 1365, Loss: 1.28128885461929\n",
            "Epoch: 1366, Loss: 1.28121657658976\n",
            "Epoch: 1367, Loss: 1.2881951188364773\n",
            "Epoch: 1368, Loss: 1.2955331988368475\n",
            "Epoch: 1369, Loss: 1.2958146917059066\n",
            "Epoch: 1370, Loss: 1.2887137621007068\n",
            "Epoch: 1371, Loss: 1.2744022438712153\n",
            "Epoch: 1372, Loss: 1.2809707847892815\n",
            "Epoch: 1373, Loss: 1.2885538305796629\n",
            "Epoch: 1374, Loss: 1.2811593096306984\n",
            "Epoch: 1375, Loss: 1.2953195631081331\n",
            "Epoch: 1376, Loss: 1.2811381715409298\n",
            "Epoch: 1377, Loss: 1.27812655766805\n",
            "Epoch: 1378, Loss: 1.2764670451482136\n",
            "Epoch: 1379, Loss: 1.288301649668538\n",
            "Epoch: 1380, Loss: 1.2953941027323406\n",
            "Epoch: 1381, Loss: 1.2947781652423507\n",
            "Epoch: 1382, Loss: 1.2842713425345453\n",
            "Epoch: 1383, Loss: 1.2811227436606765\n",
            "Epoch: 1384, Loss: 1.2872816611689033\n",
            "Epoch: 1385, Loss: 1.2745873843524473\n",
            "Epoch: 1386, Loss: 1.281276893953905\n",
            "Epoch: 1387, Loss: 1.2777520570349186\n",
            "Epoch: 1388, Loss: 1.2811523963373603\n",
            "Epoch: 1389, Loss: 1.2743643268625786\n",
            "Epoch: 1390, Loss: 1.2894311957325495\n",
            "Epoch: 1391, Loss: 1.2772982949060752\n",
            "Epoch: 1392, Loss: 1.289568911207483\n",
            "Epoch: 1393, Loss: 1.274302267013712\n",
            "Epoch: 1394, Loss: 1.3023862661199366\n",
            "Epoch: 1395, Loss: 1.2811598541043328\n",
            "Epoch: 1396, Loss: 1.296878972797529\n",
            "Epoch: 1397, Loss: 1.288023350932074\n",
            "Epoch: 1398, Loss: 1.2882784013207076\n",
            "Epoch: 1399, Loss: 1.2883254982900958\n",
            "Epoch: 1400, Loss: 1.2882544960536009\n",
            "Epoch: 1401, Loss: 1.2885779886381\n",
            "Epoch: 1402, Loss: 1.2886501618310915\n",
            "Epoch: 1403, Loss: 1.2885707151805255\n",
            "Epoch: 1404, Loss: 1.2844043209197673\n",
            "Epoch: 1405, Loss: 1.289604922558399\n",
            "Epoch: 1406, Loss: 1.2904344256042588\n",
            "Epoch: 1407, Loss: 1.2946366130882967\n",
            "Epoch: 1408, Loss: 1.2913915333172954\n",
            "Epoch: 1409, Loss: 1.2815578026128998\n",
            "Epoch: 1410, Loss: 1.2885328835629402\n",
            "Epoch: 1411, Loss: 1.2813907861709595\n",
            "Epoch: 1412, Loss: 1.2817922864399902\n",
            "Epoch: 1413, Loss: 1.2962855971451346\n",
            "Epoch: 1414, Loss: 1.3005915804112211\n",
            "Epoch: 1415, Loss: 1.2812134433299938\n",
            "Epoch: 1416, Loss: 1.2831811532906607\n",
            "Epoch: 1417, Loss: 1.2813702069275767\n",
            "Epoch: 1418, Loss: 1.2764714263009687\n",
            "Epoch: 1419, Loss: 1.2881700815038477\n",
            "Epoch: 1420, Loss: 1.3009623449744907\n",
            "Epoch: 1421, Loss: 1.2886386027572847\n",
            "Epoch: 1422, Loss: 1.2879351724124124\n",
            "Epoch: 1423, Loss: 1.3131369766614116\n",
            "Epoch: 1424, Loss: 1.2744044352930488\n",
            "Epoch: 1425, Loss: 1.2944180255240583\n",
            "Epoch: 1426, Loss: 1.281120203065534\n",
            "Epoch: 1427, Loss: 1.2811228603335982\n",
            "Epoch: 1428, Loss: 1.2824971202417468\n",
            "Epoch: 1429, Loss: 1.2792662221489224\n",
            "Epoch: 1430, Loss: 1.302178365964416\n",
            "Epoch: 1431, Loss: 1.2838720954056326\n",
            "Epoch: 1432, Loss: 1.2895422193175512\n",
            "Epoch: 1433, Loss: 1.2882607507367505\n",
            "Epoch: 1434, Loss: 1.2966924009593666\n",
            "Epoch: 1435, Loss: 1.2990996110523845\n",
            "Epoch: 1436, Loss: 1.2811043719027904\n",
            "Epoch: 1437, Loss: 1.2742509689736874\n",
            "Epoch: 1438, Loss: 1.281123803862443\n",
            "Epoch: 1439, Loss: 1.2824654663708193\n",
            "Epoch: 1440, Loss: 1.3024561946273696\n",
            "Epoch: 1441, Loss: 1.3027283020898806\n",
            "Epoch: 1442, Loss: 1.2817707678950425\n",
            "Epoch: 1443, Loss: 1.2740381068371711\n",
            "Epoch: 1444, Loss: 1.2887792189915974\n",
            "Epoch: 1445, Loss: 1.312908630844549\n",
            "Epoch: 1446, Loss: 1.2813189384785104\n",
            "Epoch: 1447, Loss: 1.2953010138044965\n",
            "Epoch: 1448, Loss: 1.2815590902423182\n",
            "Epoch: 1449, Loss: 1.295316883858214\n",
            "Epoch: 1450, Loss: 1.3023754510473697\n",
            "Epoch: 1451, Loss: 1.2931320244538869\n",
            "Epoch: 1452, Loss: 1.2826590056115008\n",
            "Epoch: 1453, Loss: 1.3081522410643016\n",
            "Epoch: 1454, Loss: 1.2811178603070847\n",
            "Epoch: 1455, Loss: 1.2905011768882155\n",
            "Epoch: 1456, Loss: 1.2756924223392567\n",
            "Epoch: 1457, Loss: 1.2817183420167746\n",
            "Epoch: 1458, Loss: 1.2839527882582753\n",
            "Epoch: 1459, Loss: 1.2959129353787036\n",
            "Epoch: 1460, Loss: 1.30301330360115\n",
            "Epoch: 1461, Loss: 1.2760522585388616\n",
            "Epoch: 1462, Loss: 1.2741371900477307\n",
            "Epoch: 1463, Loss: 1.2789124656230846\n",
            "Epoch: 1464, Loss: 1.281117467170066\n",
            "Epoch: 1465, Loss: 1.276081179896145\n",
            "Epoch: 1466, Loss: 1.2813093805989475\n",
            "Epoch: 1467, Loss: 1.295298879873668\n",
            "Epoch: 1468, Loss: 1.2811901002910966\n",
            "Epoch: 1469, Loss: 1.2818463254482189\n",
            "Epoch: 1470, Loss: 1.2811260147297636\n",
            "Epoch: 1471, Loss: 1.3006867373243292\n",
            "Epoch: 1472, Loss: 1.2811208946485046\n",
            "Epoch: 1473, Loss: 1.299964224193113\n",
            "Epoch: 1474, Loss: 1.28111643402289\n",
            "Epoch: 1475, Loss: 1.2743140357605953\n",
            "Epoch: 1476, Loss: 1.2811749818477225\n",
            "Epoch: 1477, Loss: 1.2955921651623772\n",
            "Epoch: 1478, Loss: 1.2811135053634644\n",
            "Epoch: 1479, Loss: 1.2762569003071345\n",
            "Epoch: 1480, Loss: 1.3023918672656336\n",
            "Epoch: 1481, Loss: 1.2968439176572975\n",
            "Epoch: 1482, Loss: 1.2811115481329303\n",
            "Epoch: 1483, Loss: 1.2827191648753822\n",
            "Epoch: 1484, Loss: 1.274109716956497\n",
            "Epoch: 1485, Loss: 1.2896662832151913\n",
            "Epoch: 1486, Loss: 1.2894864581155439\n",
            "Epoch: 1487, Loss: 1.2811594719582415\n",
            "Epoch: 1488, Loss: 1.2886485402465713\n",
            "Epoch: 1489, Loss: 1.274683265821308\n",
            "Epoch: 1490, Loss: 1.2811489798498492\n",
            "Epoch: 1491, Loss: 1.2811081282635952\n",
            "Epoch: 1492, Loss: 1.289041261300973\n",
            "Epoch: 1493, Loss: 1.2839904414846541\n",
            "Epoch: 1494, Loss: 1.2741045918025022\n",
            "Epoch: 1495, Loss: 1.281164045874954\n",
            "Epoch: 1496, Loss: 1.2811121357248185\n",
            "Epoch: 1497, Loss: 1.2939174166807892\n",
            "Epoch: 1498, Loss: 1.2845089063576773\n",
            "Epoch: 1499, Loss: 1.3017202294464651\n",
            "Epoch: 1500, Loss: 1.283932349360581\n",
            "Epoch: 1501, Loss: 1.2740262459355889\n",
            "Epoch: 1502, Loss: 1.2812393937550537\n",
            "Epoch: 1503, Loss: 1.2811641811479069\n",
            "Epoch: 1504, Loss: 1.287481869366152\n",
            "Epoch: 1505, Loss: 1.2882135168034978\n",
            "Epoch: 1506, Loss: 1.2743117149840009\n",
            "Epoch: 1507, Loss: 1.2906582710590768\n",
            "Epoch: 1508, Loss: 1.2883248701163217\n",
            "Epoch: 1509, Loss: 1.2879028396403536\n",
            "Epoch: 1510, Loss: 1.281273938239889\n",
            "Epoch: 1511, Loss: 1.2740523206426742\n",
            "Epoch: 1512, Loss: 1.281163734747163\n",
            "Epoch: 1513, Loss: 1.2954762878147423\n",
            "Epoch: 1514, Loss: 1.2812402316019045\n",
            "Epoch: 1515, Loss: 1.2987893151898755\n",
            "Epoch: 1516, Loss: 1.2811235612165843\n",
            "Epoch: 1517, Loss: 1.2814147075017293\n",
            "Epoch: 1518, Loss: 1.281994730022782\n",
            "Epoch: 1519, Loss: 1.2803402970023188\n",
            "Epoch: 1520, Loss: 1.2819063367573083\n",
            "Epoch: 1521, Loss: 1.2740134973052546\n",
            "Epoch: 1522, Loss: 1.2761495028827208\n",
            "Epoch: 1523, Loss: 1.274081213254455\n",
            "Epoch: 1524, Loss: 1.2813420836807143\n",
            "Epoch: 1525, Loss: 1.2883504189498036\n",
            "Epoch: 1526, Loss: 1.2881957749102977\n",
            "Epoch: 1527, Loss: 1.2887411142917389\n",
            "Epoch: 1528, Loss: 1.2960766959697643\n",
            "Epoch: 1529, Loss: 1.2743421099710126\n",
            "Epoch: 1530, Loss: 1.2880832049863558\n",
            "Epoch: 1531, Loss: 1.2829920070391174\n",
            "Epoch: 1532, Loss: 1.2893589295394032\n",
            "Epoch: 1533, Loss: 1.2882588552245011\n",
            "Epoch: 1534, Loss: 1.2881989225428154\n",
            "Epoch: 1535, Loss: 1.2750312428102426\n",
            "Epoch: 1536, Loss: 1.282002181026107\n",
            "Epoch: 1537, Loss: 1.2965986728668213\n",
            "Epoch: 1538, Loss: 1.2889058666026338\n",
            "Epoch: 1539, Loss: 1.2886432891196393\n",
            "Epoch: 1540, Loss: 1.2885255940417026\n",
            "Epoch: 1541, Loss: 1.2773850598233811\n",
            "Epoch: 1542, Loss: 1.2871790101342167\n",
            "Epoch: 1543, Loss: 1.2872889768992755\n",
            "Epoch: 1544, Loss: 1.2812686228583046\n",
            "Epoch: 1545, Loss: 1.2846125262848873\n",
            "Epoch: 1546, Loss: 1.283673640684033\n",
            "Epoch: 1547, Loss: 1.281615045899195\n",
            "Epoch: 1548, Loss: 1.288855233090989\n",
            "Epoch: 1549, Loss: 1.30530646760413\n",
            "Epoch: 1550, Loss: 1.2742652783157131\n",
            "Epoch: 1551, Loss: 1.2784805458488193\n",
            "Epoch: 1552, Loss: 1.288212722074901\n",
            "Epoch: 1553, Loss: 1.2813000450743006\n",
            "Epoch: 1554, Loss: 1.3024160464604695\n",
            "Epoch: 1555, Loss: 1.2973535153882723\n",
            "Epoch: 1556, Loss: 1.2811060695783465\n",
            "Epoch: 1557, Loss: 1.302562616395612\n",
            "Epoch: 1558, Loss: 1.2896589226756536\n",
            "Epoch: 1559, Loss: 1.3028562170393923\n",
            "Epoch: 1560, Loss: 1.2815607447996207\n",
            "Epoch: 1561, Loss: 1.274049199219291\n",
            "Epoch: 1562, Loss: 1.2897627083122307\n",
            "Epoch: 1563, Loss: 1.30244942167972\n",
            "Epoch: 1564, Loss: 1.2740605993473784\n",
            "Epoch: 1565, Loss: 1.2811031375370971\n",
            "Epoch: 1566, Loss: 1.2952881831649348\n",
            "Epoch: 1567, Loss: 1.2765872656030857\n",
            "Epoch: 1568, Loss: 1.274186984021613\n",
            "Epoch: 1569, Loss: 1.281211680554329\n",
            "Epoch: 1570, Loss: 1.2883428174553189\n",
            "Epoch: 1571, Loss: 1.2899918141939961\n",
            "Epoch: 1572, Loss: 1.2811772535878716\n",
            "Epoch: 1573, Loss: 1.2740595788820415\n",
            "Epoch: 1574, Loss: 1.3024095279950623\n",
            "Epoch: 1575, Loss: 1.2746296884320305\n",
            "Epoch: 1576, Loss: 1.3086919344908803\n",
            "Epoch: 1577, Loss: 1.2740145118523996\n",
            "Epoch: 1578, Loss: 1.2816508619497853\n",
            "Epoch: 1579, Loss: 1.3094930800985782\n",
            "Epoch: 1580, Loss: 1.2901360210797466\n",
            "Epoch: 1581, Loss: 1.2816262084541592\n",
            "Epoch: 1582, Loss: 1.2814353670634275\n",
            "Epoch: 1583, Loss: 1.2956777303776843\n",
            "Epoch: 1584, Loss: 1.2749685437966745\n",
            "Epoch: 1585, Loss: 1.309912421179156\n",
            "Epoch: 1586, Loss: 1.2818319281787738\n",
            "Epoch: 1587, Loss: 1.2740820502558499\n",
            "Epoch: 1588, Loss: 1.281125840565837\n",
            "Epoch: 1589, Loss: 1.2812187139024125\n",
            "Epoch: 1590, Loss: 1.2894979503983302\n",
            "Epoch: 1591, Loss: 1.2987572834001364\n",
            "Epoch: 1592, Loss: 1.2952942687568936\n",
            "Epoch: 1593, Loss: 1.288231667051924\n",
            "Epoch: 1594, Loss: 1.295304018554958\n",
            "Epoch: 1595, Loss: 1.2812195145492011\n",
            "Epoch: 1596, Loss: 1.2810444688120632\n",
            "Epoch: 1597, Loss: 1.3033888390723696\n",
            "Epoch: 1598, Loss: 1.2887005738332762\n",
            "Epoch: 1599, Loss: 1.3089425935812875\n",
            "Epoch: 1600, Loss: 1.2882107530079834\n",
            "Epoch: 1601, Loss: 1.281110758477069\n",
            "Epoch: 1602, Loss: 1.2776491075542802\n",
            "Epoch: 1603, Loss: 1.2740258697076892\n",
            "Epoch: 1604, Loss: 1.281272865356283\n",
            "Epoch: 1605, Loss: 1.2797081656489813\n",
            "Epoch: 1606, Loss: 1.2882709528537506\n",
            "Epoch: 1607, Loss: 1.2811242629450263\n",
            "Epoch: 1608, Loss: 1.281109238347263\n",
            "Epoch: 1609, Loss: 1.2811205826752574\n",
            "Epoch: 1610, Loss: 1.2926319989752262\n",
            "Epoch: 1611, Loss: 1.2812868263704558\n",
            "Epoch: 1612, Loss: 1.2740107309733721\n",
            "Epoch: 1613, Loss: 1.2912065179635446\n",
            "Epoch: 1614, Loss: 1.2889937517490793\n",
            "Epoch: 1615, Loss: 1.2917873385950183\n",
            "Epoch: 1616, Loss: 1.2882609350461487\n",
            "Epoch: 1617, Loss: 1.2811408558635846\n",
            "Epoch: 1618, Loss: 1.2811581809469994\n",
            "Epoch: 1619, Loss: 1.2890370314848338\n",
            "Epoch: 1620, Loss: 1.3028406226043159\n",
            "Epoch: 1621, Loss: 1.2882066694557244\n",
            "Epoch: 1622, Loss: 1.2833690465764795\n",
            "Epoch: 1623, Loss: 1.2811123014341854\n",
            "Epoch: 1624, Loss: 1.2881965628752472\n",
            "Epoch: 1625, Loss: 1.295289397239685\n",
            "Epoch: 1626, Loss: 1.2881958214103753\n",
            "Epoch: 1627, Loss: 1.2811224299965176\n",
            "Epoch: 1628, Loss: 1.2811425256390943\n",
            "Epoch: 1629, Loss: 1.281141274364282\n",
            "Epoch: 1630, Loss: 1.2853602128671415\n",
            "Epoch: 1631, Loss: 1.2882016263109572\n",
            "Epoch: 1632, Loss: 1.2901805757630802\n",
            "Epoch: 1633, Loss: 1.2881999041171783\n",
            "Epoch: 1634, Loss: 1.274104987475889\n",
            "Epoch: 1635, Loss: 1.288280002614285\n",
            "Epoch: 1636, Loss: 1.301594412073176\n",
            "Epoch: 1637, Loss: 1.3080648538914132\n",
            "Epoch: 1638, Loss: 1.2740150318078116\n",
            "Epoch: 1639, Loss: 1.2814707265678027\n",
            "Epoch: 1640, Loss: 1.2757078831922923\n",
            "Epoch: 1641, Loss: 1.274088736121536\n",
            "Epoch: 1642, Loss: 1.2867635480055573\n",
            "Epoch: 1643, Loss: 1.2881951323637726\n",
            "Epoch: 1644, Loss: 1.275840938514006\n",
            "Epoch: 1645, Loss: 1.2877086823713695\n",
            "Epoch: 1646, Loss: 1.2811301769094263\n",
            "Epoch: 1647, Loss: 1.2811096974298464\n",
            "Epoch: 1648, Loss: 1.2872200671662675\n",
            "Epoch: 1649, Loss: 1.2953266395744703\n",
            "Epoch: 1650, Loss: 1.2754195074663095\n",
            "Epoch: 1651, Loss: 1.2826432488488813\n",
            "Epoch: 1652, Loss: 1.284486857711846\n",
            "Epoch: 1653, Loss: 1.2953079008887\n",
            "Epoch: 1654, Loss: 1.2880641289636598\n",
            "Epoch: 1655, Loss: 1.2811267130763817\n",
            "Epoch: 1656, Loss: 1.309478632101776\n",
            "Epoch: 1657, Loss: 1.3020930087312739\n",
            "Epoch: 1658, Loss: 1.2890216154409637\n",
            "Epoch: 1659, Loss: 1.2881952118366322\n",
            "Epoch: 1660, Loss: 1.282371499014239\n",
            "Epoch: 1661, Loss: 1.2760491159790797\n",
            "Epoch: 1662, Loss: 1.2953740079352196\n",
            "Epoch: 1663, Loss: 1.2811037285108093\n",
            "Epoch: 1664, Loss: 1.2943370764982616\n",
            "Epoch: 1665, Loss: 1.27448618581109\n",
            "Epoch: 1666, Loss: 1.2922066483937256\n",
            "Epoch: 1667, Loss: 1.2951387192340607\n",
            "Epoch: 1668, Loss: 1.274051509004958\n",
            "Epoch: 1669, Loss: 1.28601436581172\n",
            "Epoch: 1670, Loss: 1.2946949546218764\n",
            "Epoch: 1671, Loss: 1.295415383704165\n",
            "Epoch: 1672, Loss: 1.304828702135289\n",
            "Epoch: 1673, Loss: 1.281116176158824\n",
            "Epoch: 1674, Loss: 1.2740219932921388\n",
            "Epoch: 1675, Loss: 1.291412871780125\n",
            "Epoch: 1676, Loss: 1.2847095727920532\n",
            "Epoch: 1677, Loss: 1.288658766036338\n",
            "Epoch: 1678, Loss: 1.2959038653272263\n",
            "Epoch: 1679, Loss: 1.2750008376777595\n",
            "Epoch: 1680, Loss: 1.3095275670924085\n",
            "Epoch: 1681, Loss: 1.281124418508922\n",
            "Epoch: 1682, Loss: 1.2830248775211632\n",
            "Epoch: 1683, Loss: 1.2751355881386615\n",
            "Epoch: 1684, Loss: 1.295739731044634\n",
            "Epoch: 1685, Loss: 1.2811693773202018\n",
            "Epoch: 1686, Loss: 1.2740665665755035\n",
            "Epoch: 1687, Loss: 1.281566820246108\n",
            "Epoch: 1688, Loss: 1.2882068309378116\n",
            "Epoch: 1689, Loss: 1.2815256617593427\n",
            "Epoch: 1690, Loss: 1.2883163580657742\n",
            "Epoch: 1691, Loss: 1.2836956225388438\n",
            "Epoch: 1692, Loss: 1.3026089059545638\n",
            "Epoch: 1693, Loss: 1.282754138006386\n",
            "Epoch: 1694, Loss: 1.2957704785867785\n",
            "Epoch: 1695, Loss: 1.2830518078296742\n",
            "Epoch: 1696, Loss: 1.2816462964876323\n",
            "Epoch: 1697, Loss: 1.2815312113322264\n",
            "Epoch: 1698, Loss: 1.2743632319971179\n",
            "Epoch: 1699, Loss: 1.2954439161517095\n",
            "Epoch: 1700, Loss: 1.288248321688767\n",
            "Epoch: 1701, Loss: 1.2864092985788982\n",
            "Epoch: 1702, Loss: 1.292519856851997\n",
            "Epoch: 1703, Loss: 1.2744475078920945\n",
            "Epoch: 1704, Loss: 1.2881972231763474\n",
            "Epoch: 1705, Loss: 1.2825761788280297\n",
            "Epoch: 1706, Loss: 1.2819457967230614\n",
            "Epoch: 1707, Loss: 1.283660351807344\n",
            "Epoch: 1708, Loss: 1.3024461700561198\n",
            "Epoch: 1709, Loss: 1.2953251794720373\n",
            "Epoch: 1710, Loss: 1.2882706366532237\n",
            "Epoch: 1711, Loss: 1.2954954991103909\n",
            "Epoch: 1712, Loss: 1.2880454503052623\n",
            "Epoch: 1713, Loss: 1.2882057436814545\n",
            "Epoch: 1714, Loss: 1.2811714884237195\n",
            "Epoch: 1715, Loss: 1.2813436604560688\n",
            "Epoch: 1716, Loss: 1.2882487934531894\n",
            "Epoch: 1717, Loss: 1.2821971220327606\n",
            "Epoch: 1718, Loss: 1.277497929038731\n",
            "Epoch: 1719, Loss: 1.28094338017998\n",
            "Epoch: 1720, Loss: 1.2811033472101738\n",
            "Epoch: 1721, Loss: 1.2958425266522888\n",
            "Epoch: 1722, Loss: 1.281105286686133\n",
            "Epoch: 1723, Loss: 1.2811452387072515\n",
            "Epoch: 1724, Loss: 1.2878163055325231\n",
            "Epoch: 1725, Loss: 1.285731518522222\n",
            "Epoch: 1726, Loss: 1.2882169307546412\n",
            "Epoch: 1727, Loss: 1.2811039686203003\n",
            "Epoch: 1728, Loss: 1.2740231997577856\n",
            "Epoch: 1729, Loss: 1.2846088333332792\n",
            "Epoch: 1730, Loss: 1.281102255726537\n",
            "Epoch: 1731, Loss: 1.2846918976898734\n",
            "Epoch: 1732, Loss: 1.2811098428482706\n",
            "Epoch: 1733, Loss: 1.2884195924650692\n",
            "Epoch: 1734, Loss: 1.2740160133821745\n",
            "Epoch: 1735, Loss: 1.2897127334107743\n",
            "Epoch: 1736, Loss: 1.2949818837727214\n",
            "Epoch: 1737, Loss: 1.2811029211003728\n",
            "Epoch: 1738, Loss: 1.2811286373341337\n",
            "Epoch: 1739, Loss: 1.2811155868760238\n",
            "Epoch: 1740, Loss: 1.296062652946364\n",
            "Epoch: 1741, Loss: 1.2846611493022728\n",
            "Epoch: 1742, Loss: 1.3023837491975607\n",
            "Epoch: 1743, Loss: 1.286732052234893\n",
            "Epoch: 1744, Loss: 1.3030432023055165\n",
            "Epoch: 1745, Loss: 1.2884108293141032\n",
            "Epoch: 1746, Loss: 1.2977897258515054\n",
            "Epoch: 1747, Loss: 1.281229685384331\n",
            "Epoch: 1748, Loss: 1.2952886118111036\n",
            "Epoch: 1749, Loss: 1.2746420168707557\n",
            "Epoch: 1750, Loss: 1.2882067861286461\n",
            "Epoch: 1751, Loss: 1.2741037877738899\n",
            "Epoch: 1752, Loss: 1.2890747506567772\n",
            "Epoch: 1753, Loss: 1.2812308960772576\n",
            "Epoch: 1754, Loss: 1.2815810196788597\n",
            "Epoch: 1755, Loss: 1.279003251528909\n",
            "Epoch: 1756, Loss: 1.2811115641965933\n",
            "Epoch: 1757, Loss: 1.3095047719089696\n",
            "Epoch: 1758, Loss: 1.288203643568864\n",
            "Epoch: 1759, Loss: 1.2812475338049814\n",
            "Epoch: 1760, Loss: 1.2882017074747287\n",
            "Epoch: 1761, Loss: 1.2740208333265697\n",
            "Epoch: 1762, Loss: 1.279765080898366\n",
            "Epoch: 1763, Loss: 1.2740178657761703\n",
            "Epoch: 1764, Loss: 1.2881981683961043\n",
            "Epoch: 1765, Loss: 1.2741544348128298\n",
            "Epoch: 1766, Loss: 1.2816338327759547\n",
            "Epoch: 1767, Loss: 1.2885263270520149\n",
            "Epoch: 1768, Loss: 1.2740296844049548\n",
            "Epoch: 1769, Loss: 1.2850296970800306\n",
            "Epoch: 1770, Loss: 1.2740131988593026\n",
            "Epoch: 1771, Loss: 1.2811464155819399\n",
            "Epoch: 1772, Loss: 1.274224985575845\n",
            "Epoch: 1773, Loss: 1.281114991675032\n",
            "Epoch: 1774, Loss: 1.2883237118416644\n",
            "Epoch: 1775, Loss: 1.287699986011424\n",
            "Epoch: 1776, Loss: 1.2811070689072845\n",
            "Epoch: 1777, Loss: 1.2881410324827154\n",
            "Epoch: 1778, Loss: 1.2811198437467535\n",
            "Epoch: 1779, Loss: 1.282763367003583\n",
            "Epoch: 1780, Loss: 1.2809352257573012\n",
            "Epoch: 1781, Loss: 1.274220459850122\n",
            "Epoch: 1782, Loss: 1.2740295026319246\n",
            "Epoch: 1783, Loss: 1.2885352592941717\n",
            "Epoch: 1784, Loss: 1.2882089378140495\n",
            "Epoch: 1785, Loss: 1.2883997969593561\n",
            "Epoch: 1786, Loss: 1.2882040629150173\n",
            "Epoch: 1787, Loss: 1.2741689073278548\n",
            "Epoch: 1788, Loss: 1.2903871688436954\n",
            "Epoch: 1789, Loss: 1.2740731602864908\n",
            "Epoch: 1790, Loss: 1.2755257136432836\n",
            "Epoch: 1791, Loss: 1.2871975002559364\n",
            "Epoch: 1792, Loss: 1.2882425658246304\n",
            "Epoch: 1793, Loss: 1.2740807262718254\n",
            "Epoch: 1794, Loss: 1.274123822543638\n",
            "Epoch: 1795, Loss: 1.296952837747885\n",
            "Epoch: 1796, Loss: 1.2743097256261406\n",
            "Epoch: 1797, Loss: 1.2740288939036375\n",
            "Epoch: 1798, Loss: 1.2882690564960453\n",
            "Epoch: 1799, Loss: 1.2952981806815937\n",
            "Epoch: 1800, Loss: 1.2895063787487382\n",
            "Epoch: 1801, Loss: 1.2881331993332992\n",
            "Epoch: 1802, Loss: 1.2953368383096464\n",
            "Epoch: 1803, Loss: 1.2746057747103643\n",
            "Epoch: 1804, Loss: 1.2911149643837136\n",
            "Epoch: 1805, Loss: 1.2883921548829855\n",
            "Epoch: 1806, Loss: 1.285231520098152\n",
            "Epoch: 1807, Loss: 1.3031708365636514\n",
            "Epoch: 1808, Loss: 1.2740114589109488\n",
            "Epoch: 1809, Loss: 1.2832706752398335\n",
            "Epoch: 1810, Loss: 1.2960594985501985\n",
            "Epoch: 1811, Loss: 1.2947111653943433\n",
            "Epoch: 1812, Loss: 1.2816633138250797\n",
            "Epoch: 1813, Loss: 1.2818431888066284\n",
            "Epoch: 1814, Loss: 1.2892977210646825\n",
            "Epoch: 1815, Loss: 1.288195382618735\n",
            "Epoch: 1816, Loss: 1.283910424151319\n",
            "Epoch: 1817, Loss: 1.295305143856833\n",
            "Epoch: 1818, Loss: 1.2811927947592228\n",
            "Epoch: 1819, Loss: 1.2816086567885487\n",
            "Epoch: 1820, Loss: 1.2889270004651225\n",
            "Epoch: 1821, Loss: 1.2949801522789273\n",
            "Epoch: 1822, Loss: 1.2807352263876732\n",
            "Epoch: 1823, Loss: 1.2814178999434125\n",
            "Epoch: 1824, Loss: 1.2814160188039143\n",
            "Epoch: 1825, Loss: 1.2743956941239376\n",
            "Epoch: 1826, Loss: 1.2740420339800786\n",
            "Epoch: 1827, Loss: 1.2811986732144727\n",
            "Epoch: 1828, Loss: 1.2740695256713435\n",
            "Epoch: 1829, Loss: 1.2936427779231512\n",
            "Epoch: 1830, Loss: 1.2814711154775416\n",
            "Epoch: 1831, Loss: 1.2821143924767244\n",
            "Epoch: 1832, Loss: 1.274239532490994\n",
            "Epoch: 1833, Loss: 1.2952896627128547\n",
            "Epoch: 1834, Loss: 1.2742445519629946\n",
            "Epoch: 1835, Loss: 1.2811020274534293\n",
            "Epoch: 1836, Loss: 1.2972669313985405\n",
            "Epoch: 1837, Loss: 1.3023766524402807\n",
            "Epoch: 1838, Loss: 1.2811715831147863\n",
            "Epoch: 1839, Loss: 1.2902861926572542\n",
            "Epoch: 1840, Loss: 1.2881996623167755\n",
            "Epoch: 1841, Loss: 1.2819178172037111\n",
            "Epoch: 1842, Loss: 1.281620422153608\n",
            "Epoch: 1843, Loss: 1.2825261582719518\n",
            "Epoch: 1844, Loss: 1.2883322644740978\n",
            "Epoch: 1845, Loss: 1.2813645322272118\n",
            "Epoch: 1846, Loss: 1.2811057609869232\n",
            "Epoch: 1847, Loss: 1.2881948339178206\n",
            "Epoch: 1848, Loss: 1.2740583884800578\n",
            "Epoch: 1849, Loss: 1.2742280317536483\n",
            "Epoch: 1850, Loss: 1.2953041901825166\n",
            "Epoch: 1851, Loss: 1.2919328238101715\n",
            "Epoch: 1852, Loss: 1.2801029648341185\n",
            "Epoch: 1853, Loss: 1.2811185290627445\n",
            "Epoch: 1854, Loss: 1.2818912622776437\n",
            "Epoch: 1855, Loss: 1.2849056999734108\n",
            "Epoch: 1856, Loss: 1.281306357248455\n",
            "Epoch: 1857, Loss: 1.3024604565708349\n",
            "Epoch: 1858, Loss: 1.3100309211311612\n",
            "Epoch: 1859, Loss: 1.2740294459863757\n",
            "Epoch: 1860, Loss: 1.2818447723456308\n",
            "Epoch: 1861, Loss: 1.2955429173530415\n",
            "Epoch: 1862, Loss: 1.2813466432246756\n",
            "Epoch: 1863, Loss: 1.28733488346668\n",
            "Epoch: 1864, Loss: 1.302512452112022\n",
            "Epoch: 1865, Loss: 1.2759495686132012\n",
            "Epoch: 1866, Loss: 1.2811699843575768\n",
            "Epoch: 1867, Loss: 1.2882115147637982\n",
            "Epoch: 1868, Loss: 1.2811575510823134\n",
            "Epoch: 1869, Loss: 1.2881996995168374\n",
            "Epoch: 1870, Loss: 1.30278280694434\n",
            "Epoch: 1871, Loss: 1.290153721545605\n",
            "Epoch: 1872, Loss: 1.282727484161972\n",
            "Epoch: 1873, Loss: 1.2881735453368923\n",
            "Epoch: 1874, Loss: 1.288188730571287\n",
            "Epoch: 1875, Loss: 1.2889267231555694\n",
            "Epoch: 1876, Loss: 1.288973867470491\n",
            "Epoch: 1877, Loss: 1.2953131739974868\n",
            "Epoch: 1878, Loss: 1.2839655521068167\n",
            "Epoch: 1879, Loss: 1.3013654380825395\n",
            "Epoch: 1880, Loss: 1.2882050453348362\n",
            "Epoch: 1881, Loss: 1.2811067349521825\n",
            "Epoch: 1882, Loss: 1.2882252103048013\n",
            "Epoch: 1883, Loss: 1.2810300478698513\n",
            "Epoch: 1884, Loss: 1.2815218656621081\n",
            "Epoch: 1885, Loss: 1.2881938252888672\n",
            "Epoch: 1886, Loss: 1.2954412698745728\n",
            "Epoch: 1887, Loss: 1.2949161740905004\n",
            "Epoch: 1888, Loss: 1.2811108455590323\n",
            "Epoch: 1889, Loss: 1.2811018017166895\n",
            "Epoch: 1890, Loss: 1.2812297327298645\n",
            "Epoch: 1891, Loss: 1.2740124261125605\n",
            "Epoch: 1892, Loss: 1.288196065747146\n",
            "Epoch: 1893, Loss: 1.2881943562352065\n",
            "Epoch: 1894, Loss: 1.2952391991378567\n",
            "Epoch: 1895, Loss: 1.2948086819750197\n",
            "Epoch: 1896, Loss: 1.2740121175211372\n",
            "Epoch: 1897, Loss: 1.2813524455888896\n",
            "Epoch: 1898, Loss: 1.281151810436384\n",
            "Epoch: 1899, Loss: 1.288234458747485\n",
            "Epoch: 1900, Loss: 1.2885281583096118\n",
            "Epoch: 1901, Loss: 1.2741006841050817\n",
            "Epoch: 1902, Loss: 1.2882310710054763\n",
            "Epoch: 1903, Loss: 1.288872758547465\n",
            "Epoch: 1904, Loss: 1.2811244218907458\n",
            "Epoch: 1905, Loss: 1.2883497950033094\n",
            "Epoch: 1906, Loss: 1.2892456900143454\n",
            "Epoch: 1907, Loss: 1.2801555327489866\n",
            "Epoch: 1908, Loss: 1.2952904033322705\n",
            "Epoch: 1909, Loss: 1.2999909422921796\n",
            "Epoch: 1910, Loss: 1.2885246217673552\n",
            "Epoch: 1911, Loss: 1.3015995008725647\n",
            "Epoch: 1912, Loss: 1.2818765395076561\n",
            "Epoch: 1913, Loss: 1.274034153485129\n",
            "Epoch: 1914, Loss: 1.2771234123419362\n",
            "Epoch: 1915, Loss: 1.2882604404544153\n",
            "Epoch: 1916, Loss: 1.2952907634965072\n",
            "Epoch: 1917, Loss: 1.2956544778025743\n",
            "Epoch: 1918, Loss: 1.2870025812311374\n",
            "Epoch: 1919, Loss: 1.2838547542585548\n",
            "Epoch: 1920, Loss: 1.2882339092011148\n",
            "Epoch: 1921, Loss: 1.281594197800819\n",
            "Epoch: 1922, Loss: 1.2740796161881576\n",
            "Epoch: 1923, Loss: 1.288365587275079\n",
            "Epoch: 1924, Loss: 1.2945824396525714\n",
            "Epoch: 1925, Loss: 1.2881223267697273\n",
            "Epoch: 1926, Loss: 1.295688084676756\n",
            "Epoch: 1927, Loss: 1.2811695328840973\n",
            "Epoch: 1928, Loss: 1.2979299489487992\n",
            "Epoch: 1929, Loss: 1.281163640056096\n",
            "Epoch: 1930, Loss: 1.2811297288177705\n",
            "Epoch: 1931, Loss: 1.2811109546228503\n",
            "Epoch: 1932, Loss: 1.2947178918419155\n",
            "Epoch: 1933, Loss: 1.2899569847905044\n",
            "Epoch: 1934, Loss: 1.2884821629693322\n",
            "Epoch: 1935, Loss: 1.3029565591338679\n",
            "Epoch: 1936, Loss: 1.2834591738721157\n",
            "Epoch: 1937, Loss: 1.2954910866757656\n",
            "Epoch: 1938, Loss: 1.2886263740823625\n",
            "Epoch: 1939, Loss: 1.2811742353101148\n",
            "Epoch: 1940, Loss: 1.2953156723198316\n",
            "Epoch: 1941, Loss: 1.2740745561342712\n",
            "Epoch: 1942, Loss: 1.2749456970404225\n",
            "Epoch: 1943, Loss: 1.2882422191876892\n",
            "Epoch: 1944, Loss: 1.2892217458562647\n",
            "Epoch: 1945, Loss: 1.295316385884657\n",
            "Epoch: 1946, Loss: 1.2844809462838138\n",
            "Epoch: 1947, Loss: 1.3020331952588777\n",
            "Epoch: 1948, Loss: 1.3021208698867905\n",
            "Epoch: 1949, Loss: 1.2881947324631062\n",
            "Epoch: 1950, Loss: 1.2740136038327048\n",
            "Epoch: 1951, Loss: 1.2881934541337032\n",
            "Epoch: 1952, Loss: 1.2740380425825186\n",
            "Epoch: 1953, Loss: 1.274098182400913\n",
            "Epoch: 1954, Loss: 1.2812928553168654\n",
            "Epoch: 1955, Loss: 1.2741214146850801\n",
            "Epoch: 1956, Loss: 1.274074322788428\n",
            "Epoch: 1957, Loss: 1.2967152215064839\n",
            "Epoch: 1958, Loss: 1.2811058201688401\n",
            "Epoch: 1959, Loss: 1.281197041484481\n",
            "Epoch: 1960, Loss: 1.2745797042305587\n",
            "Epoch: 1961, Loss: 1.2800107712441302\n",
            "Epoch: 1962, Loss: 1.2811597974587838\n",
            "Epoch: 1963, Loss: 1.2811181257802544\n",
            "Epoch: 1964, Loss: 1.2868874478847423\n",
            "Epoch: 1965, Loss: 1.281750498933995\n",
            "Epoch: 1966, Loss: 1.2811360934101943\n",
            "Epoch: 1967, Loss: 1.300687939562696\n",
            "Epoch: 1968, Loss: 1.288236861533307\n",
            "Epoch: 1969, Loss: 1.309471050052778\n",
            "Epoch: 1970, Loss: 1.2842538382144684\n",
            "Epoch: 1971, Loss: 1.3017797055819356\n",
            "Epoch: 1972, Loss: 1.2882204816696492\n",
            "Epoch: 1973, Loss: 1.288197048166965\n",
            "Epoch: 1974, Loss: 1.2882809748886324\n",
            "Epoch: 1975, Loss: 1.2881994966074084\n",
            "Epoch: 1976, Loss: 1.2905220503502703\n",
            "Epoch: 1977, Loss: 1.2741170479050765\n",
            "Epoch: 1978, Loss: 1.295288751311336\n",
            "Epoch: 1979, Loss: 1.2811592166305434\n",
            "Epoch: 1980, Loss: 1.2882449305649344\n",
            "Epoch: 1981, Loss: 1.2740458486773443\n",
            "Epoch: 1982, Loss: 1.295037604392843\n",
            "Epoch: 1983, Loss: 1.2952978475719479\n",
            "Epoch: 1984, Loss: 1.2741021315256755\n",
            "Epoch: 1985, Loss: 1.3091904178578802\n",
            "Epoch: 1986, Loss: 1.295513964713888\n",
            "Epoch: 1987, Loss: 1.2816678606872016\n",
            "Epoch: 1988, Loss: 1.2881964791751077\n",
            "Epoch: 1989, Loss: 1.309456837092731\n",
            "Epoch: 1990, Loss: 1.281190664210218\n",
            "Epoch: 1991, Loss: 1.2910437972833078\n",
            "Epoch: 1992, Loss: 1.2811125609891634\n",
            "Epoch: 1993, Loss: 1.2811048301399177\n",
            "Epoch: 1994, Loss: 1.2971293782511502\n",
            "Epoch: 1995, Loss: 1.279775819034441\n",
            "Epoch: 1996, Loss: 1.2949768169551876\n",
            "Epoch: 1997, Loss: 1.275499497745054\n",
            "Epoch: 1998, Loss: 1.281218394320062\n",
            "Epoch: 1999, Loss: 1.2950681498710146\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = DiagnosisNetwork().to(device)\n",
        "print(device)\n",
        "\n",
        "lossfn = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(model.parameters())\n",
        "#optim = torch.optim.SGD(model.parameters(), lr=.1, momentum=.9)\n",
        "\n",
        "for epoch in range(2000):\n",
        "  for batch in train_dl:\n",
        "    # grab data\n",
        "    X, y = batch\n",
        "    input_2d_array, input_scalar = X\n",
        "\n",
        "    # Reshape mode size for network\n",
        "    input_scalar = input_scalar.unsqueeze(1)\n",
        "\n",
        "    # Correct types and send to device\n",
        "    input_scalar = input_scalar.float()\n",
        "    input_2d_array, input_scalar, y = input_2d_array.to(device), input_scalar.to(device), y.to(device)\n",
        "    #input_2d_array, y = input_2d_array.to(device), y.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    pred_probab = model(input_2d_array, input_scalar)\n",
        "    #pred_probab = model(input_2d_array)\n",
        "\n",
        "    # calculate loss\n",
        "    loss = lossfn(pred_probab, y)\n",
        "\n",
        "    # backpropagation\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "  # print loss for each epoch\n",
        "  print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RRhyIAtlSrH",
        "outputId": "d29896fb-076b-4dfe-8895-b97a2b566294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "356\n",
            "411\n",
            "accuracy: 86.61800486618006%\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for batch in test_dl:\n",
        "        # grab data\n",
        "        X, y = batch\n",
        "        input_2d_array, input_scalar = X\n",
        "\n",
        "        # Reshape image and mode size for network\n",
        "        input_scalar = input_scalar.unsqueeze(1)\n",
        "\n",
        "        # Correct types and send to device\n",
        "        input_scalar = input_scalar.float()\n",
        "        input_2d_array, input_scalar, y = input_2d_array.to(device), input_scalar.to(device), y.to(device)\n",
        "        input_2d_array, y = input_2d_array.to(device), y.to(device)\n",
        "\n",
        "        pred_probab = model(input_2d_array, input_scalar)\n",
        "        yhat = pred_probab.argmax(1).float()\n",
        "        total += y.size(0)\n",
        "        correct += (yhat == y.argmax(1)).sum().item()\n",
        "print(correct)\n",
        "print(total)\n",
        "accuracy = 100 * (correct/total)\n",
        "print(f\"accuracy: {accuracy}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
